# -*- coding: utf-8 -*-
"""Project 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ujHd7fw_sAXb2dA7MGab0ZysPXYxvtAC

# Project 2 - Star Type Classification - Wilfredo Aaron Sosa Ramos

# Connect the project with Google Drive
To achieve our dataset
"""

#Mount the google drive connection to our dataset
from google.colab import drive
drive.mount('/content/drive')

"""# Phase 1: Extract

# Load our Dataset
"""

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/AI/Project 2/dataset/cleaned_star_data.csv')

"""# Check our Dataset"""

df

""" Star Type:
*   0 -> Brown Type
*   1 -> Red Dwarf
*   2 -> White Dwarf
*   3 -> Main Sequence
*   4 -> Supergiants
*   5 -> Hypergiants
"""

df.head()

"""# Dataset metadata"""

df.info()

"""# Dataset statistical info."""

df.describe()

"""# Dataset Shape (Rows x Columns)"""

df.shape

"""# Number of unique values per column (Dimension)"""

df.nunique()

"""# Number of values and null rows per each column"""

for c in df.columns:
  print(c)
  print(df[c].value_counts())

df.isnull().sum()

"""# Correlation per each column"""

df.corr()

"""# Phase 2: Transform

1. Duplicated data
"""

df.duplicated()

df_no_duplicated = df.drop_duplicates()
df_no_duplicated.shape

"""2. Empty data"""

df_no_na = df_no_duplicated.dropna()
df_no_na.shape

"""3. Encode categorical dimensions (With Feature Engineering)"""

df_no_na["Star color"].unique()

df_no_na["Spectral Class"].unique()

"""# Encoding Pipeline (Star color with One Hot Encoder and Spectral Class with Ordinal Encoder)

Prepare the categorical columns
"""

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

categorical_columns = ['Star color', 'Spectral Class']
onehot_transformer = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
ordinal_transformer = OrdinalEncoder(categories=[df_no_na["Spectral Class"].unique()])

"""Create the Pre-Processor"""

from sklearn.compose import ColumnTransformer

preprocessor = ColumnTransformer(
    transformers=[
        ('onehot', onehot_transformer, ['Star color']),
        ('ordinal', ordinal_transformer, ['Spectral Class'])
    ])

"""Create the Pipeline"""

from sklearn.pipeline import Pipeline
pipeline = Pipeline(steps=[('preprocessor', preprocessor)])

df_encoded = pipeline.fit_transform(df_no_na)

df_encoded = pd.DataFrame(df_encoded, columns=pipeline.named_steps['preprocessor'].get_feature_names_out())
df_final_encoded = df_no_na.copy()

df_final_encoded.drop("Star color", axis=1, inplace=True)
df_final_encoded.drop("Spectral Class", axis=1, inplace=True)
df_final_encoded = pd.concat([df_final_encoded,df_encoded], axis=1)
df_final_encoded

df_final_encoded.info()

"""# Detecting outliers

Statistical Graphics
"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(x='Star type', y='Luminosity(L/Lo)', data=df_final_encoded)
plt.title('Box Plot - Luminosity (L/Lo) by Star Type')
plt.show()

sns.scatterplot(x='Radius(R/Ro)', y='Temperature (K)', hue='Star type', data=df_final_encoded)
plt.title('Scatter Plot - Radius vs Temperature by Star Type')
plt.show()

sns.kdeplot(x='Absolute magnitude(Mv)', hue='Star type', data=df_final_encoded, fill=True)
plt.title('Kernel Density Plot - Absolute Magnitude by Star Type')
plt.show()

sns.boxplot(x='Star type', y='Luminosity(L/Lo)', data=df_final_encoded)
plt.title('Box Plot - Luminosity (L/Lo) by Star Type')
plt.show()

sns.boxplot(x='Star type', y='Radius(R/Ro)', data=df_final_encoded)
plt.title('Box Plot - Radius (R/Ro) by Star Type')
plt.show()

sns.pairplot(df_final_encoded[['Temperature (K)', 'Luminosity(L/Lo)', 'Radius(R/Ro)', 'Absolute magnitude(Mv)', 'Star type']], hue='Star type')
plt.suptitle('Pair Plot - Numeric Variables by Star Type', y=1.02)
plt.show()

sns.boxplot(x='Star type', y='Absolute magnitude(Mv)', data=df_final_encoded)
plt.title('Box Plot - Absolute Magnitude by Star Type')
plt.show()

"""Z-Score"""

from scipy.stats import zscore

z_scores = zscore(df_final_encoded[['Temperature (K)', 'Luminosity(L/Lo)', 'Radius(R/Ro)', 'Absolute magnitude(Mv)']])

print(df_final_encoded.shape)

df_no_outliers_zscore = df_final_encoded[(z_scores < 3).all(axis=1)]

print(df_no_outliers_zscore.shape)

"""Isolation Forest"""

from sklearn.ensemble import IsolationForest

df_no_outliers_zscore = df_no_outliers_zscore.copy()

isolation_forest = IsolationForest(contamination=0.05)
df_no_outliers_zscore['outlier_isolation_forest'] = isolation_forest.fit_predict(df_no_outliers_zscore[['Temperature (K)', 'Luminosity(L/Lo)', 'Radius(R/Ro)', 'Absolute magnitude(Mv)']])

df_no_outliers_isolation_forest = df_no_outliers_zscore[df_no_outliers_zscore['outlier_isolation_forest'] != -1]

df_no_outliers_isolation_forest = df_no_outliers_isolation_forest.drop('outlier_isolation_forest', axis=1)
df_no_outliers_zscore = df_no_outliers_zscore.drop('outlier_isolation_forest', axis=1)

print(df_no_outliers_isolation_forest.shape)

"""# Phase 3: Load

Alternative 1: LogisticRegression
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

X = df_no_outliers_isolation_forest.drop("Star type", axis=1)
y = df_no_outliers_isolation_forest['Star type']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

"""StandardScaler with a Pipeline"""

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

preprocessor = ColumnTransformer(
    transformers=[
        ('standard_scaler', StandardScaler(), X.columns),
    ])

"""Develop the Pipeline"""

logistic_regression_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                            ('classifier', LogisticRegression(max_iter=1000, random_state=42))])

logistic_regression_pipeline.fit(X_train, y_train)
y_pred = logistic_regression_pipeline.predict(X_test)

"""Loss Function => Cross Validation"""

from sklearn.model_selection import cross_val_score

y_val_pred = logistic_regression_pipeline.predict(X_val)
accuracy_val = accuracy_score(y_val, y_val_pred)
classification_report_val = classification_report(y_val, y_val_pred)

print(f'Accuracy on the validation set: {accuracy_val}')
print(f'Classification Report on the validation set:\n{classification_report_val}')

cross_val_scores = cross_val_score(logistic_regression_pipeline, X, y, cv=5, scoring='accuracy')
print(f'Cross-Validation Accuracy Scores: {cross_val_scores}')

y_test_pred = logistic_regression_pipeline.predict(X_test)
accuracy_test = accuracy_score(y_test, y_test_pred)
classification_report_test = classification_report(y_test, y_test_pred)

print(f'Accuracy on the test set: {accuracy_test}')
print(f'Classification Report on the test set:\n{classification_report_test}')

"""Alternative 2: LinearSVC"""

X = df_no_outliers_isolation_forest.drop("Star type", axis=1)
y = df_no_outliers_isolation_forest['Star type']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from sklearn.model_selection import GridSearchCV
from sklearn.svm import LinearSVC
pipeline = Pipeline(steps = [
    ('preprocessor', preprocessor),
    ('svm', LinearSVC())
])

param_grid = {
    'svm__max_iter': [1000, 2000, 3000, 4000, 5000]
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Best value of max_iter:", grid_search.best_params_)
print("Accuracy with the best value of max_iter:", grid_search.best_score_)

from sklearn.svm import LinearSVC

linear_svc_pipeline_hinge = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', LinearSVC(loss='hinge', max_iter=1000))])
linear_svc_pipeline_hinge.fit(X_train, y_train)

linear_svc_pipeline_log = Pipeline(steps=[('preprocessor', preprocessor),
                               ('classifier', LinearSVC(loss='squared_hinge', max_iter=1000))])
linear_svc_pipeline_log.fit(X_train, y_train)

y_pred_train_hinge = linear_svc_pipeline_hinge.predict(X_train)
y_pred_val_hinge = linear_svc_pipeline_hinge.predict(X_val)
y_pred_test_hinge = linear_svc_pipeline_hinge.predict(X_test)

y_pred_train_log = linear_svc_pipeline_log.predict(X_train)
y_pred_val_log = linear_svc_pipeline_log.predict(X_val)
y_pred_test_log = linear_svc_pipeline_log.predict(X_test)

accuracy_train_hinge = accuracy_score(y_train, y_pred_train_hinge)
accuracy_val_hinge = accuracy_score(y_val, y_pred_val_hinge)
accuracy_test_hinge = accuracy_score(y_test, y_pred_test_hinge)

accuracy_train_log = accuracy_score(y_train, y_pred_train_log)
accuracy_val_log = accuracy_score(y_val, y_pred_val_log)
accuracy_test_log = accuracy_score(y_test, y_pred_test_log)

import numpy as np
print("Results using hinge loss:")
print("Accuracy (training):", accuracy_train_hinge)
print("Accuracy (validation):", accuracy_val_hinge)
print("Accuracy (test):", accuracy_test_hinge)
print("\nClassification Report (test):")
print(classification_report(y_test, y_pred_test_hinge))

print("\nResults using log loss:")
print("Accuracy (training):", accuracy_train_log)
print("Accuracy (validation):", accuracy_val_log)
print("Accuracy (test):", accuracy_test_log)
print("\nClassification Report (test):")
print(classification_report(y_test, y_pred_test_log))

cv_scores_hinge = cross_val_score(linear_svc_pipeline_hinge, X, y, cv=5)
cv_scores_log = cross_val_score(linear_svc_pipeline_log, X, y, cv=5)

print("\nCross-validation accuracy (hinge loss):", np.mean(cv_scores_hinge))
print("Cross-validation accuracy (log loss):", np.mean(cv_scores_log))

"""Alternative 3: Random Forest Classifier"""

X = df_no_outliers_isolation_forest.drop("Star type", axis=1)
y = df_no_outliers_isolation_forest['Star type']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from sklearn.ensemble import RandomForestClassifier

random_forest_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', RandomForestClassifier())])
random_forest_pipeline.fit(X_train, y_train)

y_pred_train = random_forest_pipeline.predict(X_train)
y_pred_val = random_forest_pipeline.predict(X_val)
y_pred_test = random_forest_pipeline.predict(X_test)

"""Loss Function => Gini Impurity"""

def gini_impurity(y_true, y_pred):
    total_samples = len(y_true)
    class_counts = {}
    for label in y_true:
        if label not in class_counts:
            class_counts[label] = 0
        class_counts[label] += 1

    gini = 1.0
    for label in class_counts:
        label_prob = class_counts[label] / total_samples
        gini -= label_prob ** 2

    return gini

from sklearn.metrics import make_scorer

gini_scorer = make_scorer(gini_impurity, greater_is_better=True)

validation_gini = gini_impurity(y_val, y_pred_val)
test_gini = gini_impurity(y_test, y_pred_test)
cross_val_scores = cross_val_score(random_forest_pipeline, X_train, y_train, cv=5, scoring=gini_scorer)
mean_cross_val_gini = cross_val_scores.mean()

print("Gini Impurity for Validation Dataset: ",validation_gini)
print("Gini Impurity for Test Dataset: ",test_gini)
print("Gini Impurity for Cross-Validation: ",mean_cross_val_gini)

"""Loss Function => Entropy"""

def entropy(y_true, y_pred):
    total_samples = len(y_true)
    class_counts = {}
    for label in y_true:
        if label not in class_counts:
            class_counts[label] = 0
        class_counts[label] += 1

    entropy_value = 0.0
    for label in class_counts:
        label_prob = class_counts[label] / total_samples
        entropy_value -= label_prob * np.log2(label_prob)

    return entropy_value

entropy_scorer = make_scorer(entropy, greater_is_better=False)
validation_entropy = entropy(y_val, y_val_pred)
test_entropy = entropy(y_test, y_pred_test)
cross_val_scores_entropy = cross_val_score(random_forest_pipeline, X_train, y_train, cv=5, scoring=entropy_scorer)
mean_cross_val_entropy = cross_val_scores_entropy.mean()

print("Entropy for Validation Dataset: ",validation_entropy)
print("Entropy for Test Dataset: ",test_entropy)
print("Entropy for Cross-Validation: ",mean_cross_val_entropy)

"""Alternative 4 - KNN (K-Nearest Neighbors)"""

X = df_no_outliers_isolation_forest.drop("Star type", axis=1)
y = df_no_outliers_isolation_forest['Star type']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from sklearn.neighbors import KNeighborsClassifier

knn_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', KNeighborsClassifier())])
knn_pipeline.fit(X_train, y_train)

"""Loss Functions => Accuracy and Cross Entropy"""

from sklearn.metrics import accuracy_score, log_loss
from sklearn.model_selection import cross_val_score

y_val_pred = knn_pipeline.predict(X_val)
accuracy_val = accuracy_score(y_val, y_val_pred)

y_val_proba = knn_pipeline.predict_proba(X_val)
cross_entropy_val = log_loss(y_val, y_val_proba)

y_test_pred = knn_pipeline.predict(X_test)
accuracy_test = accuracy_score(y_test, y_test_pred)

y_test_proba = knn_pipeline.predict_proba(X_test)
cross_entropy_test = log_loss(y_test, y_test_proba)

cross_val_scores = cross_val_score(knn_pipeline, X_train, y_train, cv=5, scoring='accuracy')
average_accuracy_cv = cross_val_scores.mean()

print("Accuracy on Validation Set:", accuracy_val)
print("Cross Entropy Loss on Validation Set:", cross_entropy_val)
print("Accuracy on Test Set:", accuracy_test)
print("Cross Entropy Loss on Test Set:", cross_entropy_test)
print("Average Accuracy using Cross-Validation:", average_accuracy_cv)

"""Alternative 5 - Gradient Boosting Classifier"""

X = df_no_outliers_isolation_forest.drop("Star type", axis=1)
y = df_no_outliers_isolation_forest['Star type']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from sklearn.ensemble import GradientBoostingClassifier

gradient_boosting_classifier = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', GradientBoostingClassifier())])
gradient_boosting_classifier.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, log_loss
from sklearn.model_selection import cross_val_score

y_val_pred = gradient_boosting_classifier.predict(X_val)
accuracy_val = accuracy_score(y_val, y_val_pred)

y_val_proba = gradient_boosting_classifier.predict_proba(X_val)
cross_entropy_val = log_loss(y_val, y_val_proba)

y_test_pred = gradient_boosting_classifier.predict(X_test)
accuracy_test = accuracy_score(y_test, y_test_pred)

y_test_proba = gradient_boosting_classifier.predict_proba(X_test)
cross_entropy_test = log_loss(y_test, y_test_proba)

cross_val_scores = cross_val_score(gradient_boosting_classifier, X_train, y_train, cv=5, scoring='accuracy')
average_accuracy_cv = cross_val_scores.mean()

print("Accuracy on Validation Set:", accuracy_val)
print("Cross Entropy Loss on Validation Set:", cross_entropy_val)
print("Accuracy on Test Set:", accuracy_test)
print("Cross Entropy Loss on Test Set:", cross_entropy_test)
print("Average Accuracy using Cross-Validation:", average_accuracy_cv)

"""# Predictions"""

df_no_outliers_isolation_forest.iloc[156]

import pandas as pd

data = {
    'Temperature (K)': [37800.00],
    'Luminosity(L/Lo)': [202900.00],
    'Radius(R/Ro)': [6.86],
    'Absolute magnitude(Mv)': [-4.56],
    'onehot__Star color_Blue': [1.00],
    'onehot__Star color_Blue-White': [0.00],
    'onehot__Star color_Red': [0.00],
    'onehot__Star color_White': [0.00],
    'onehot__Star color_Yellow-White': [0.00],
    'ordinal__Spectral Class': [4.00]
}

df_for_test = pd.DataFrame(data)

log_pred = logistic_regression_pipeline.predict(df_for_test)
print("Logistic Regression result: ", log_pred)

linear_svc_hinge_pred = linear_svc_pipeline_hinge.predict(df_for_test)
print("Linear SVC - Hinge result: ", linear_svc_hinge_pred)

linear_svc_log_pred = linear_svc_pipeline_log.predict(df_for_test)
print("Linear SVC - Log result: ", linear_svc_log_pred)

random_forest_pred = random_forest_pipeline.predict(df_for_test)
print("Random Forest Classifier result: ", random_forest_pred)

knn_pred = knn_pipeline.predict(df_for_test)
print("KNN result: ", knn_pred)

gradient_boosting_pred = gradient_boosting_classifier.predict(df_for_test)
print("Gradient Boosting Classifier result: ", gradient_boosting_pred)