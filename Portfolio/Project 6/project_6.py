# -*- coding: utf-8 -*-
"""Project 6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cc5QwIdJ43uv3MMeJ-6H_P_UqzEmZaD9

# Project 6 - Wilfredo Aaron Sosa Ramos

# Data Ingestion Technique

# Phase 1: Ingest

Connect to Google Drive
"""

#Mount the google drive connection to our dataset
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""Load the dataset"""

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/AI/Project 6/dataset/jobs_in_data.csv')

df.head()

df.info()

df.describe()

df.iloc[0]

df.isnull().sum()

df.isna().sum()

"""Visualize the data"""

import matplotlib.pyplot as plt
import seaborn as sns

def plot_charts(df):
  # Numeric features
  numeric_features = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]
  for feature in numeric_features:
      plt.figure(figsize=(8, 6))
      sns.histplot(df[feature], kde=True, color='blue')
      plt.title(f'Distribution of {feature}')
      plt.xlabel(feature)
      plt.ylabel('Frequency')
      plt.show()

  # Categorical features
  categorical_features = [col for col in df.columns if df[col].dtype == 'object']
  for feature in categorical_features:
      plt.figure(figsize=(8, 6))
      sns.countplot(y=df[feature], order=df[feature].value_counts().index, palette='Set2')
      plt.title(f'Count of {feature}')
      plt.xlabel('Count')
      plt.ylabel(feature)
      plt.show()

plot_charts(df)

df.drop(["job_title", "employee_residence", "company_location"], axis=1, inplace=True)
plot_charts(df)

df.info()

"""Categorical variables:"""

df["job_category"].unique()

df["salary_currency"].unique()

df["experience_level"].unique()

df["employment_type"].unique()

df["work_setting"].unique()

df["company_size"].unique()

sns.pairplot(df, hue='company_size', aspect=1.5)
plt.show()

"""# Phase 2: Filter/Clean"""

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
ordinal_features=['job_category', 'salary_currency', "experience_level", "employment_type", "work_setting", "company_size"]

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent'))
])

ordinal_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OrdinalEncoder())
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('ordinal', ordinal_transformer, ordinal_features)
    ])

"""Elbow Point (https://www.kaggle.com/code/fazilbtopal/popular-unsupervised-clustering-algorithms)

# Phase 3: Store (Load)
"""

X = preprocessor.fit_transform(df)

from sklearn.cluster import KMeans

clusters = []

for i in range(1, 20):
    km = KMeans(n_clusters=i).fit(X)
    clusters.append(km.inertia_)

fig, ax = plt.subplots(figsize=(12, 8))
sns.lineplot(x=list(range(1, 20)), y=clusters, ax=ax)
ax.set_title('Searching for Elbow')
ax.set_xlabel('Clusters')
ax.set_ylabel('Inertia')

plt.show()

"""Possible elbow points => 3 and 4 (https://www.kaggle.com/code/fazilbtopal/popular-unsupervised-clustering-algorithms)"""

km3 = KMeans(n_clusters=3).fit(X)

df['LabelsKM3'] = km3.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x='company_size', y='salary', hue='LabelsKM3',
                palette=sns.color_palette('hls', 3))
plt.title('KMeans with 3 Clusters')
plt.show()

km4 = KMeans(n_clusters=4).fit(X)

df['LabelsKM4'] = km4.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x='company_size', y='salary', hue='LabelsKM4',
                palette=sns.color_palette('hls', 4))
plt.title('KMeans with 4 Clusters')
plt.show()

"""# Hierarchical Clustering - Agglomerative"""

from sklearn.cluster import AgglomerativeClustering

agg_cls = AgglomerativeClustering(n_clusters=3, linkage='average').fit(X)

df['AGG_Labels'] = agg_cls.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x='company_size', y='salary', hue='AGG_Labels',
                palette=sns.color_palette('hls', 3))
plt.title('Agglomerative with 3 Clusters')
plt.show()

from sklearn.cluster import AgglomerativeClustering

agg_cls = AgglomerativeClustering(n_clusters=4, linkage='average').fit(X)

df['AGG_Labels4'] = agg_cls.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x='company_size', y='salary', hue='AGG_Labels4',
                palette=sns.color_palette('hls', 4))
plt.title('Agglomerative with 4 Clusters')
plt.show()

"""Distance Matrix => Contains the distance between each point to another point in the dataset (https://www.kaggle.com/code/fazilbtopal/popular-unsupervised-clustering-algorithms)"""

from scipy.cluster import hierarchy
from scipy.spatial import distance_matrix

dist = distance_matrix(X, X)
print(dist)

from sklearn.cluster import AgglomerativeClustering
hierarchical_clustering_model = AgglomerativeClustering().fit(X)
hierarchical_clustering_model

hierarchical_clustering_model.labels_

from scipy.cluster.hierarchy import dendrogram
import numpy as np

def plot_dendrogram(model, **kwargs):

    counts = np.zeros(model.children_.shape[0])
    n_samples = len(model.labels_)
    for i, merge in enumerate(model.children_):
        current_count = 0
        for child_idx in merge:
            if child_idx < n_samples:
                current_count += 1
            else:
                current_count += counts[child_idx - n_samples]
        counts[i] = current_count

    linkage_matrix = np.column_stack([model.children_, model.distances_,
                                      counts]).astype(float)

    dendrogram(linkage_matrix, **kwargs)

hierarchical_clustering_model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)
hierarchical_clustering_model = hierarchical_clustering_model.fit(X)

plt.figure(figsize=(10, 6))
plt.title('Hierarchical Clustering Dendrogram')
plot_dendrogram(hierarchical_clustering_model, truncate_mode='level', p=3)
plt.xlabel("Number of points in node (or index of point if no parenthesis).")
plt.show()

"""# Density-Based Spatial Clustering of Applications with Noise (DBSCAN)

Separations according to the density

As Fazil (2019) mentioned:

*   Epsilon determine a specified radius that if includes enough number of points within, we call it dense area minimum
*   Samples determine the minimum number of data points we want in a neighborhood to define a cluster.
"""

from sklearn.cluster import DBSCAN

db = DBSCAN(eps=11, min_samples=6).fit(X)

df['DBSCAN_Labels'] = db.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x='company_size', y='salary', hue='DBSCAN_Labels',
                palette=sns.color_palette('hls', np.unique(db.labels_).shape[0]))
plt.title('DBSCAN with epsilon 11, min samples 6')
plt.show()

db = DBSCAN(eps=11, min_samples=3).fit(X)

df['DBSCAN_Labels'] = db.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x='company_size', y='salary', hue='DBSCAN_Labels',
                palette=sns.color_palette('hls', np.unique(db.labels_).shape[0]))
plt.title('DBSCAN with epsilon 11, min samples 3')
plt.show()

"""# Mean Shift Algorithm

As Fazil (2019) mentioned:


*   Discover blobs in a smooth density of samples
*   It is a centroid based algorithm
*   It works by updating candidates for centroids to be the mean of the points within a given region
*   The algorithm automatically sets the number of clusters (estimate_bandwidth function)
"""

from sklearn.cluster import MeanShift, estimate_bandwidth

bandwidth = estimate_bandwidth(X, quantile=0.1)
ms = MeanShift(bandwidth=bandwidth).fit(X)

df['MS_Labels'] = ms.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x='company_size', y='salary', hue='MS_Labels',
                palette=sns.color_palette('hls', np.unique(ms.labels_).shape[0]))
plt.plot()
plt.title('MeanShift')
plt.show()

"""# Let's try another dataset"""

import pandas as pd
df2 = pd.read_csv('/content/drive/My Drive/AI/Project 6/dataset/customer_segmentation_train.csv')

df2.head()

df2.info()

df2.drop("ID", axis=1, inplace=True)

df2.describe()

df2.isna().sum()

df2.isnull().sum()

"""Visualize the data"""

plot_charts(df2)

numeric_features = df2.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_features = ['Gender', 'Ever_Married', 'Graduated']
ordinal_features=['Profession', 'Spending_Score', 'Var_1', 'Segmentation']

from sklearn.preprocessing import OneHotEncoder

cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor2 = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', cat_transformer, cat_features),
        ('ordinal', ordinal_transformer, ordinal_features)
    ])

X2 = preprocessor2.fit_transform(df2)

"""# K-Means Clustering"""

from sklearn.cluster import KMeans

clusters = []

for i in range(1, 20):
    km = KMeans(n_clusters=i).fit(X2)
    clusters.append(km.inertia_)

fig, ax = plt.subplots(figsize=(12, 8))
sns.lineplot(x=list(range(1, 20)), y=clusters, ax=ax)
ax.set_title('Searching for Elbow')
ax.set_xlabel('Clusters')
ax.set_ylabel('Inertia')

plt.show()

km3 = KMeans(n_clusters=3).fit(X2)

df2['LabelsKM3'] = km3.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df2, x='Age', y='Work_Experience', hue='LabelsKM3',
                palette=sns.color_palette('hls', 3))
plt.title('KMeans with 3 Clusters')
plt.show()

km4 = KMeans(n_clusters=4).fit(X2)

df2['LabelsKM4'] = km4.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df2, x='Age', y='Work_Experience', hue='LabelsKM4',
                palette=sns.color_palette('hls', 4))
plt.title('KMeans with 4 Clusters')
plt.show()

"""# Hierarchical Clustering - Agglomerative"""

from sklearn.cluster import AgglomerativeClustering

agg_cls = AgglomerativeClustering(n_clusters=3, linkage='average').fit(X2)

df2['AGG_Labels'] = agg_cls.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df2, x='Age', y='Work_Experience', hue='AGG_Labels',
                palette=sns.color_palette('hls', 3))
plt.title('Agglomerative with 3 Clusters')
plt.show()

from sklearn.cluster import AgglomerativeClustering

agg_cls = AgglomerativeClustering(n_clusters=4, linkage='average').fit(X2)

df2['AGG_Labels4'] = agg_cls.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df2, x='Age', y='Work_Experience', hue='AGG_Labels4',
                palette=sns.color_palette('hls', 4))
plt.title('Agglomerative with 4 Clusters')
plt.show()

from sklearn.cluster import AgglomerativeClustering
hierarchical_clustering_model = AgglomerativeClustering().fit(X2)
hierarchical_clustering_model

hierarchical_clustering_model.labels_

from scipy.cluster.hierarchy import dendrogram
import numpy as np

hierarchical_clustering_model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)
hierarchical_clustering_model = hierarchical_clustering_model.fit(X)

plt.figure(figsize=(10, 6))
plt.title('Hierarchical Clustering Dendrogram')
plot_dendrogram(hierarchical_clustering_model, truncate_mode='level', p=3)
plt.xlabel("Number of points in node (or index of point if no parenthesis).")
plt.show()

"""# Density-Based Spatial Clustering of Applications with Noise (DBSCAN)"""

from sklearn.cluster import DBSCAN

db2 = DBSCAN(eps=11, min_samples=6).fit(X2)

df2['DBSCAN_Labels'] = db2.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df2, x='Age', y='Work_Experience', hue='DBSCAN_Labels',
                palette=sns.color_palette('hls', np.unique(db2.labels_).shape[0]))
plt.title('DBSCAN with epsilon 11, min samples 6')
plt.show()

"""# Mean Shift Algorithm"""

from sklearn.cluster import MeanShift, estimate_bandwidth

bandwidth = estimate_bandwidth(X2, quantile=0.1)
ms = MeanShift(bandwidth=bandwidth).fit(X2)

df2['MS_Labels'] = ms.labels_
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df2, x='Age', y='Work_Experience', hue='MS_Labels',
                palette=sns.color_palette('hls', np.unique(ms.labels_).shape[0]))
plt.plot()
plt.title('MeanShift')
plt.show()