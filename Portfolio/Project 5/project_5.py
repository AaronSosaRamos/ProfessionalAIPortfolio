# -*- coding: utf-8 -*-
"""Project 5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zz9ma-J0NXO7_4hUhioiu2JoDFLkqbyP

# Project 5 - Apple Clustering - Wilfredo Aaron Sosa Ramos

# Data Ingestio Technique

# Phase 1: Ingest

Connect to Google Drive
"""

#Mount the google drive connection to our dataset
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""Load the dataset"""

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/AI/Project 5/dataset/apple_quality.csv')

df.head()

df.drop("A_id", axis=1, inplace=True)
df.drop(df.tail(1).index, inplace=True)

df.shape

df.isnull().sum()

df.isna().sum()

df.info()

"""Partition Clustering: Assume the x number of clusters and partition the data into that amount of divisions

Number of clusters is known before of performing clustering in Partition Clustering (Sundaram, 2021 => https://www.kaggle.com/code/gireeshs/complete-guide-to-clustering-techniques)

# Phase 2: Filter/Clean
"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
import pandas as pd

one_hot_cols = ['Quality']
scaled_cols = [col for col in df.columns if col not in one_hot_cols]

transformers = [
    ('one_hot', OneHotEncoder(), one_hot_cols),
    ('scaler', StandardScaler(), scaled_cols)
]

column_transformer = ColumnTransformer(transformers, remainder='passthrough')

transformed_data = column_transformer.fit_transform(df)

encoded_columns = column_transformer.named_transformers_['one_hot'].get_feature_names_out(input_features=one_hot_cols)
scaled_columns = scaled_cols
all_columns = list(encoded_columns) + scaled_columns

df_transformed = pd.DataFrame(transformed_data, columns=all_columns)

df_transformed.head()

df_transformed.info()

"""# Phase 3: Store (Load)"""

from sklearn.cluster import KMeans

km = KMeans(init="random", n_clusters=3)
km.fit(df_transformed)

km.cluster_centers_

km.labels_

"""Solution of the optimal number of clusters (https://www.kaggle.com/code/gireeshs/complete-guide-to-clustering-techniques)"""

import matplotlib.pyplot as plt

distortions = []
K = range(1, 20)
for k in K:
    kmeanModel = KMeans(n_clusters=k)
    kmeanModel.fit(df_transformed)
    distortions.append(kmeanModel.inertia_)

plt.plot(K, distortions, 'bx-')
plt.xlabel('No of clusters (k)')
plt.ylabel('Distortion')
plt.title('The Elbow Method showing the optimal k')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.cluster import KMeans

dimensions = ["Quality_good", "Size", "Juiciness"]

X = df_transformed[dimensions]

kmeans = KMeans(n_clusters=8, init='k-means++')
kmeans.fit(X)

centers = kmeans.cluster_centers_
labels = kmeans.labels_

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

for label in range(8):
    ax.scatter(X.loc[labels == label, dimensions[0]],
               X.loc[labels == label, dimensions[1]],
               X.loc[labels == label, dimensions[2]],
               label=f'Cluster {label + 1}')

ax.scatter(centers[:, 0], centers[:, 1], centers[:, 2], s=200, c='black', marker='*', label='Cluster Centers')

ax.set_xlabel(dimensions[0])
ax.set_ylabel(dimensions[1])
ax.set_zlabel(dimensions[2])
ax.set_title('3D Clustering of Data')

plt.legend()
plt.show()