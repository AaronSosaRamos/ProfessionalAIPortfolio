# -*- coding: utf-8 -*-
"""Project 10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pf0ABu1MHCF544JzbEIVTrWVVblZTTtR

# Project 10 - Visualization - Wilfredo Aaron Sosa Ramos

#Data Engineering Lifecycle

#Phase 1: Ingestion
"""

#Mount the google drive connection to our dataset
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/AI/Project 10/dataset/abalone.csv')

"""# Phase 2: Transformation"""

import matplotlib.pyplot as plt
import seaborn as sns

def plot_charts(df):
  # Numeric features
  numeric_features = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]
  for feature in numeric_features:
      plt.figure(figsize=(8, 6))
      sns.histplot(df[feature], kde=True, color='blue')
      plt.title(f'Distribution of {feature}')
      plt.xlabel(feature)
      plt.ylabel('Frequency')
      plt.show()

  # Categorical features
  categorical_features = [col for col in df.columns if df[col].dtype == 'object']
  for feature in categorical_features:
      plt.figure(figsize=(8, 6))
      sns.countplot(y=df[feature], order=df[feature].value_counts().index, palette='Set2')
      plt.title(f'Count of {feature}')
      plt.xlabel('Count')
      plt.ylabel(feature)
      plt.show()

plot_charts(df)

numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_features = df.select_dtypes(include=['object']).columns.tolist()

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
import pandas as pd

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent'))
])

cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', cat_transformer, cat_features)
    ])

df_encoded = preprocessor.fit_transform(df)

new_column_names = preprocessor.named_transformers_['cat'] \
    .named_steps['encoder'].get_feature_names_out(input_features=cat_features)

new_column_names

columns = df.columns.tolist()

columns

columns.remove("Type")

columns

columns.extend(new_column_names.tolist())

columns

df_encoded = pd.DataFrame(df_encoded, columns=columns)

df_encoded.head()

X = df_encoded.drop("Type_F", axis=1)
y = df_encoded["Type_F"]

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

"""# Phase 3: Serving

#t-distributed Stochastic Neighbor Embedding (t-SNE)

Only in 2 components
"""

from sklearn.manifold import TSNE
import time

tsne = TSNE(n_components = 2, random_state = 42)
t0 = time.time()
X_reduced = tsne.fit_transform(X_train)
t1 = time.time()

t1-t0

plt.figure(figsize=(12, 8))
plt.scatter(X_reduced[:,0], X_reduced[:,1], c = y_train, cmap='jet')
plt.colorbar()
plt.axis('off')
plt.show()

"""Only 0 and 1"""

idx = (y_train == 0) | (y_train == 1)
X_subset = X_train[idx]
y_subset = y_train[idx]

tsne_subset = TSNE(n_components=2, random_state=42)
X_subset_reduced = tsne_subset.fit_transform(X_subset)

plt.figure(figsize=(9,9))
for digit in (0, 1):
    plt.scatter(X_subset_reduced[y_subset == digit, 0], X_subset_reduced[y_subset == digit, 1] )
plt.axis('off')
plt.show()

"""# PCA Visualization"""

from sklearn.decomposition import PCA
pca = PCA(n_components = 2)
t0 = time.time()
X_pca = pca.fit_transform(X_train)
t1 = time.time()
print(t1-t0)

plt.figure(figsize=(12, 8))
plt.scatter(X_pca[:,0], X_pca[:,1], c = y_train, cmap='jet')
plt.colorbar()
plt.axis('off')
plt.show()

"""# PCA + T-SNE"""

from sklearn.pipeline import Pipeline

pca_tsne = Pipeline([
    ('pca', PCA(n_components=0.95, random_state=42)),
    ('tsne', TSNE(n_components=2, random_state=42)),
])
t0 = time.time()
X_pca_tsne = pca_tsne.fit_transform(X_train)
t1 = time.time()
print(t1-t0)

plt.figure(figsize=(12, 8))
plt.scatter(X_reduced[:,0], X_reduced[:,1], c = y_train, cmap='jet')
plt.colorbar()
plt.axis('off')
plt.show()

"""# Locally Linear Embedding (LLE)"""

from sklearn.manifold import LocallyLinearEmbedding
t0 = time.time()
X_lle = LocallyLinearEmbedding(n_components=2, random_state=42).fit_transform(X_train)
t1 = time.time()
print(t1 - t0)

plt.figure(figsize=(12, 8))
plt.scatter(X_lle[:,0], X_lle[:,1], c = y_train, cmap='jet')
plt.colorbar()
plt.axis('off')
plt.show()

"""#PCA + LLE"""

pca_lle = Pipeline([
    ("pca", PCA(n_components=0.95, random_state=42)),
    ("lle", LocallyLinearEmbedding(n_components=2, random_state=42, eigen_solver='dense')),
])
t0 = time.time()
X_pca_lle = pca_lle.fit_transform(X_train)
t1 = time.time()
print(t1-t0)

plt.figure(figsize=(12, 8))
plt.scatter(X_pca_lle[:,0], X_pca_lle[:,1], c = y_train, cmap='jet')
plt.colorbar()
plt.axis('off')
plt.show()

"""#Linear Discriminant Analysis (LDA)"""

import numpy as np

n_features = X_train.shape[1]
n_classes = len(np.unique(y_train))

n_classes

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

max_components = min(n_features, n_classes - 1)

t0 = time.time()
X_lda = LinearDiscriminantAnalysis(n_components=max_components).fit_transform(X_train, y_train)
t1 = time.time()
print(t1 - t0)

plt.figure(figsize=(12, 8))
plt.scatter(X_pca_lle[:,0], X_pca_lle[:,1], c = y_train, cmap='jet')
plt.colorbar()
plt.axis('off')
plt.show()