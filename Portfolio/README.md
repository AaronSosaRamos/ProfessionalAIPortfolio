# Professional AI Portfolio

Welcome to my Professional AI Portfolio! This repository showcases detailed projects in Machine Learning (ML), Deep Learning (DL), HuggingFace Large Language Models (LLMs), and Computer Vision (CV). Below is an overview of each project, demonstrating my expertise and experience in various AI domains.

## Projects

### Project 1: Obesity Predictor
- **Techniques:** ETL (Extract, Transform, Load), Grid Search Cross Validation (GridCV), Mean Squared Error (MSE)
- **Algorithms:** Logistic Regression, Linear SVC, Random Forest Regression, Linear Regression
- **Description:** 
  - **Objective:** Develop a predictive model to determine obesity levels based on health and demographic metrics.
  - **Data Handling:** Performed ETL processes to clean and transform raw health data into a usable format.
  - **Model Development:** Implemented multiple ML algorithms including Logistic Regression for classification, Linear SVC for support vector classification, and regression algorithms like Random Forest Regression and Linear Regression.
  - **Model Tuning and Evaluation:** Used GridCV to fine-tune hyperparameters and MSE for evaluating model performance.

### Project 2: Star Type Classification
- **Techniques:** ETL, GridCV
- **Algorithms:** Logistic Regression, Linear SVC, Random Forest Classifier, K-Nearest Neighbors (KNN), Gradient Boosting Classifier
- **Description:** 
  - **Objective:** Classify stars into different types based on their physical and spectral characteristics.
  - **Data Handling:** Executed ETL operations to preprocess astronomical data, ensuring it was clean and properly formatted.
  - **Model Development:** Experimented with various classification algorithms, including Logistic Regression, Linear SVC, Random Forest Classifier, KNN, and Gradient Boosting Classifier.
  - **Model Tuning:** Applied GridCV for hyperparameter tuning to optimize each model's performance.

### Project 3: Hotel KPIs and Critical Dimensions Models
- **Techniques:** ETL, GridCV
- **Algorithms:** MultiOutputRegressor with RandomForestRegressor, Single models for KPIs (Lead time with RandomForestRegressor, GradientBoostingRegressor, XGBoost), MultiOutputClassifier with RandomForestClassifier
- **Description:** 
  - **Objective:** Predict various hotel KPIs such as lead time, cancellation rates, and booking tendencies.
  - **Data Handling:** Conducted ETL processes to extract, transform, and load hotel data into a structured format.
  - **Model Development:** Built multiple models to predict KPIs. Implemented MultiOutputRegressor to predict multiple KPIs simultaneously and individual models for specific KPIs using RandomForestRegressor, GradientBoostingRegressor, and XGBoost.
  - **Model Tuning:** Utilized GridCV for hyperparameter tuning and model selection to improve accuracy and reliability.

### Project 4: Apple Quality Classification
- **Techniques:** Professional ML pipelines, GridCV, Cross Validation, RandomizedSearchCV, Ensemble Methods
- **Algorithms:** LightGBM, XGBoost
- **Description:** 
  - **Objective:** Classify the quality of apples based on physical and sensory attributes.
  - **Data Handling:** Designed professional ML pipelines for data ingestion, preprocessing, and feature extraction.
  - **Model Development:** Employed advanced algorithms like LightGBM and XGBoost for classification.
  - **Model Tuning:** Fine-tuned models using GridCV and RandomizedSearchCV, and applied ensemble methods to enhance predictive performance.
  - **Evaluation:** Conducted cross-validation to ensure model robustness and generalizability.

### Project 5: Apple Clustering for Unsupervised Learning
- **Techniques:** Data Ingestion
- **Algorithms:** K-Means Clustering, Hierarchical Clustering, Spectral Clustering
- **Description:** 
  - **Objective:** Identify natural groupings of apples based on their characteristics.
  - **Data Handling:** Implemented data ingestion techniques to collect and preprocess apple data.
  - **Model Development:** Applied various clustering algorithms including K-Means, Hierarchical Clustering, and Spectral Clustering.
  - **Evaluation:** Analyzed clustering results to understand different apple groupings and their features.

### Project 6: Clustering Algorithms and Techniques
- **Techniques:** Data Ingestion
- **Algorithms:** Agglomerative Clustering, Density-Based Spatial Clustering of Applications with Noise (DBSCAN), Mean Shift Algorithm, K-Means Clustering, Elbow Analysis
- **Description:** 
  - **Objective:** Explore and compare different clustering algorithms to group data points effectively.
  - **Data Handling:** Used data ingestion techniques for preprocessing.
  - **Model Development:** Implemented a variety of clustering algorithms including Agglomerative Clustering, DBSCAN, Mean Shift, and K-Means.
  - **Evaluation:** Performed elbow analysis to determine the optimal number of clusters and compared the performance of each algorithm.

### Project 7: Anomaly Detection
- **Techniques:** Data Engineering Lifecycle, ML Pipelines for Data Processing, Normalization, Standardization, Model Training
- **Algorithms:** Robust Covariance, Isolation Forest, One-Class SVM, Local Outlier Factor
- **Description:** 
  - **Objective:** Detect anomalies in datasets, identifying outliers that deviate from normal patterns.
  - **Data Handling:** Followed a data engineering lifecycle, including data processing, normalization, and standardization.
  - **Model Development:** Implemented various anomaly detection algorithms such as Robust Covariance, Isolation Forest, One-Class SVM, and Local Outlier Factor.
  - **Evaluation:** Trained models and evaluated their ability to accurately detect anomalies in the data.

### Project 8: Anomaly and Novelty Detection
- **Techniques:** Data Engineering Lifecycle
- **Algorithms:** Isolation Forest, Local Outlier Factor
- **Description:** 
  - **Objective:** Focus on detecting both anomalies and novel data points that differ from the established patterns.
  - **Data Handling:** Employed a comprehensive data engineering approach for preprocessing and analysis.
  - **Model Development:** Utilized Isolation Forest and Local Outlier Factor for robust anomaly and novelty detection.
  - **Evaluation:** Assessed model performance in identifying both anomalies and novel instances in the dataset.

### Project 9: Dimensionality Reduction
- **Techniques:** Multiple ML Pipelines
- **Algorithms:** Principal Component Analysis (PCA), Kernel PCA, RandomForestClassifier, SoftmaxClassifier
- **Description:** 
  - **Objective:** Reduce the dimensionality of datasets while retaining essential information.
  - **Data Handling:** Built multiple ML pipelines for data preprocessing and feature extraction.
  - **Model Development:** Applied dimensionality reduction techniques such as PCA and Kernel PCA.
  - **Evaluation:** Evaluated the impact of dimensionality reduction on the performance of classification models like RandomForestClassifier and SoftmaxClassifier.

### Project 10: Data Visualization
- **Techniques:** ML Pipelines (Imputers, Encoders)
- **Algorithms:** t-distributed Stochastic Neighbor Embedding (t-SNE), PCA Visualization, PCA + t-SNE, Locally Linear Embedding (LLE), PCA + LLE, Linear Discriminant Analysis (LDA)
- **Description:** 
  - **Objective:** Create visual representations of complex datasets to aid in understanding and interpretation.
  - **Data Handling:** Used ML pipelines for data imputation and encoding.
  - **Model Development:** Applied various visualization techniques including t-SNE, PCA, LLE, and LDA.
  - **Evaluation:** Generated visualizations to highlight patterns and relationships in the data, combining techniques for enhanced insight.

### Project 11: Association Rule Learning
- **Techniques:** Reusable Models with Functions
- **Algorithms:** Multi-Layer Perceptron (MLP), Random Forest Classifier, Gradient Boosting Classifier, XGBoost with Random Forest, XGBoost, Logistic Classifier, Decision Tree Classifier, Linear SVC, SVC, K-Nearest Neighbors, Naive Bayes, Ada Boost Classifier, LightGBM Classifier, Linear Discriminant Analysis, Quadratic Discriminant Analysis, Gaussian Process Classifier, Apriori Algorithm, Eclat Algorithm
- **Description:** 
  - **Objective:** Discover interesting relationships between variables in large datasets.
  - **Data Handling:** Developed reusable models and functions to streamline the learning process.
  - **Model Development:** Implemented a wide range of classification algorithms to identify association rules.
  - **Evaluation:** Used Apriori and Eclat algorithms to extract rules and evaluate their significance and applicability.

### Project 12: Semi-Supervised Learning Classification
- **Techniques:** Google AI Human-Centered Design Approach
- **Algorithms:** Logistic Regression, Label Propagation, Label Spreading, Pseudo-Labelling
- **Description:** 
  - **Objective:** Develop classification models using semi-supervised learning techniques to leverage both labeled and unlabeled data.
  - **Data Handling:** Followed Google’s human-centered design principles for model development.
  - **Model Development:** Implemented algorithms like Logistic Regression, Label Propagation, Label Spreading, and Pseudo-Labelling.
  - **Evaluation:** Assessed the models’ performance in scenarios with limited labeled data, improving usability and effectiveness.

### Project 13: Semi-Supervised Learning Regression
- **Techniques:** Google AI Human-Centered Design Approach
- **Algorithms:** Pseudo-Labelling
- **Description:** 
  - **Objective:** Focus on regression tasks using semi-supervised learning techniques.
  - **Data Handling:** Applied human-centered design principles for data handling and model development.
  - **Model Development:** Utilized pseudo-labelling to enhance regression model accuracy with limited labeled data.
  - **Evaluation:** Evaluated the models on their ability to make accurate predictions in semi-supervised scenarios.

### Project 14: Introduction to Deep Reinforcement Learning
- **Techniques:** Markov Decision Processes (MDPs)
- **Algorithms:** QLearningAgent, Convolutional Neural Networks (CNNs)
- **Datasets:** MNIST
- **Description:** 
  - **Objective:** Introduce the fundamentals of deep reinforcement learning using MDPs.
  - **Data Handling:** Employed the MNIST dataset for practical applications.
  - **Model Development:** Implemented Q-learning agents and CNN architectures to solve reinforcement learning problems.
  - **Evaluation:** Conducted experiments to understand the behavior of reinforcement learning agents and their performance on the MNIST dataset.

### Project 15: CNN with CIFAR-10 Dataset
- **Techniques:** CNN Architectures
- **Datasets:** CIFAR-10, Fashion MNIST, OXFORD Flowers 102
- **Description:** 
  - **Objective:** Train and fine-tune CNN models on multiple datasets for image classification tasks.
  - **Data Handling:** Managed datasets including CIFAR-10, Fashion MNIST, and OXFORD Flowers 102.
  - **Model Development:** Built and optimized CNN architectures to achieve high accuracy.
  - **Evaluation:** Applied best practices and techniques to improve model performance across different datasets.

### Project 16: CNN with CIFAR-100 Dataset
- **Techniques:** CNN Architectures
- **Datasets:** CIFAR-100
- **Description:** 
  - **Objective:** Extend CNN training to the CIFAR-100 dataset, which includes a larger number of categories.
  - **Data Handling:** Preprocessed CIFAR-100 data for training.
  - **Model Development:** Implemented CNN models, addressing the complexity of classifying 100 categories.
  - **Evaluation:** Fine-tuned models to optimize performance, handling the increased difficulty of the CIFAR-100 dataset.

### Project 17: CNN with CIFAR-10, Best Practices and Real Applications for Image Detection
- **Techniques:** CNN Architectures
- **Datasets:** CIFAR-10
- **Description:** 
  - **Objective:** Apply CNNs to real-world image detection tasks using the CIFAR-10 dataset.
  - **Data Handling:** Utilized CIFAR-10 for practical applications.
  - **Model Development:** Focused on best practices and advanced techniques for training and deploying CNNs.
  - **Evaluation:** Assessed model performance in real-world scenarios, emphasizing practical applications and high accuracy.

### Project 18: RNN with HuggingFace Transformers
- **Applications:** Sentiment Analysis, Speech Recognizer
- **Description:** 
  - **Objective:** Implement Recurrent Neural Networks (RNNs) using HuggingFace Transformers for NLP tasks.
  - **Data Handling:** Processed datasets for sentiment analysis and speech recognition.
  - **Model Development:** Built RNN models leveraging HuggingFace Transformers for state-of-the-art performance.
  - **Evaluation:** Evaluated models on their ability to perform sentiment analysis and speech recognition accurately.

### Project 19: Advanced CV with Document Image Classification
- **Applications:** Document Parsing, Document Visual Question Answering (DocVQA)
- **Description:** 
  - **Objective:** Explore advanced computer vision techniques for document image classification.
  - **Data Handling:** Managed document images for classification tasks.
  - **Model Development:** Implemented models for document parsing and visual question answering (DocVQA).
  - **Evaluation:** Pushed the boundaries of CV applications by developing robust models for complex document-related tasks.