{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6FLH2PY8IrDnNidhuxxrv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Computing Gradients Using Autodiff"],"metadata":{"id":"HYrmYeSehQoL"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"QHR0Hm7GgRMv","executionInfo":{"status":"ok","timestamp":1715093297542,"user_tz":300,"elapsed":4223,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"outputs":[],"source":["import tensorflow as tf\n","\n","def f(w1, w2):\n"," return 3 * w1 ** 2 + 2 * w1 * w2\n","\n","w1, w2 = 5, 3\n","eps = 1e-6\n","(f(w1 + eps, w2) - f(w1, w2)) / eps\n","(f(w1, w2 + eps) - f(w1, w2)) / eps\n","\n","w1, w2 = tf.Variable(5.), tf.Variable(3.)\n","with tf.GradientTape() as tape:\n"," z = f(w1, w2)\n","gradients = tape.gradient(z, [w1, w2])\n","\n","with tf.GradientTape() as tape:\n"," z = f(w1, w2)\n"," dz_dw1 = tape.gradient(z, w1) # => tensor 36.0"]},{"cell_type":"code","source":["dz_dw1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcecVQoahu_4","executionInfo":{"status":"ok","timestamp":1715093305018,"user_tz":300,"elapsed":6,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"e8abec07-f5ec-4972-f709-689b0d72ca68"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=36.0>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["with tf.GradientTape(persistent=True) as tape:\n"," z = f(w1, w2)\n","dz_dw1 = tape.gradient(z, w1) # => tensor 36.0\n","dz_dw2 = tape.gradient(z, w2) # => tensor 10.0, works fine now!\n","del tape"],"metadata":{"id":"eL5H8S-Xhwy2","executionInfo":{"status":"ok","timestamp":1715093324585,"user_tz":300,"elapsed":318,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["dz_dw1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zaVvrl4whyO2","executionInfo":{"status":"ok","timestamp":1715093326010,"user_tz":300,"elapsed":7,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"f14e434c-ebd3-42b4-cc03-e832d5a7fdd6"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=36.0>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["dz_dw2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvWUs9w7hzH2","executionInfo":{"status":"ok","timestamp":1715093327546,"user_tz":300,"elapsed":6,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"b87f7d6c-de08-47b5-fe9a-8268d0461029"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=10.0>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["c1, c2 = tf.constant(5.), tf.constant(3.)\n","with tf.GradientTape() as tape:\n"," z = f(c1, c2)\n","gradients = tape.gradient(z, [c1, c2])"],"metadata":{"id":"_apYAg-fh2hm","executionInfo":{"status":"ok","timestamp":1715093339667,"user_tz":300,"elapsed":4,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["gradients"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JguPTfJh4T_","executionInfo":{"status":"ok","timestamp":1715093343103,"user_tz":300,"elapsed":3,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"3a519b6c-d2cd-4d9b-be13-db6f46eeb58f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[None, None]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["with tf.GradientTape() as tape:\n"," tape.watch(c1)\n"," tape.watch(c2)\n"," z = f(c1, c2)\n","gradients = tape.gradient(z, [c1, c2])"],"metadata":{"id":"djAk-Zqsh555","executionInfo":{"status":"ok","timestamp":1715093354472,"user_tz":300,"elapsed":4,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["gradients"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Os-KywjliKoC","executionInfo":{"status":"ok","timestamp":1715093417928,"user_tz":300,"elapsed":7,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"891e974b-63fc-40b7-af83-1b97eaeefa11"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n"," <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["with tf.GradientTape(persistent=True) as hessian_tape:\n"," with tf.GradientTape() as jacobian_tape:\n","  z = f(w1, w2)\n"," jacobians = jacobian_tape.gradient(z, [w1, w2])\n","hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n"," for jacobian in jacobians]\n","del hessian_tape"],"metadata":{"id":"VmkdBu8iiOTb","executionInfo":{"status":"ok","timestamp":1715093447152,"user_tz":300,"elapsed":464,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["hessians"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fw_2aO72iSo6","executionInfo":{"status":"ok","timestamp":1715093454537,"user_tz":300,"elapsed":5,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"95d36444-a2bb-4007-f66e-ea786de80d4c"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n","  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n"," [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["def f(w1, w2):\n"," return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n","with tf.GradientTape() as tape:\n"," z = f(w1, w2) # same result as without stop_gradient()\n","gradients = tape.gradient(z, [w1, w2]) # => returns [tensor 30., None]"],"metadata":{"id":"cbGclIVxiWOM","executionInfo":{"status":"ok","timestamp":1715093473468,"user_tz":300,"elapsed":3,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["gradients"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83YhYTCQiYwD","executionInfo":{"status":"ok","timestamp":1715093476036,"user_tz":300,"elapsed":5,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"3d78c16c-6509-42ee-a3a2-73d799ef07ba"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["@tf.custom_gradient\n","def my_better_softplus(z):\n"," exp = tf.exp(z)\n"," def my_softplus_gradients(grad):\n","  return grad / (1 + 1 / exp)\n"," return tf.math.log(exp + 1), my_softplus_gradients\n","\n","x = tf.Variable([100.])\n","with tf.GradientTape() as tape:\n","  z = my_better_softplus(x)\n","\n","tape.gradient(z, [x])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"plnWmmDzi8Pg","executionInfo":{"status":"ok","timestamp":1715093976689,"user_tz":300,"elapsed":450,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"e89e0df6-1f8d-4997-ad37-76c033193731"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Custom Training Loops\n"],"metadata":{"id":"O8_0JB9fkg-F"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Define the neural network architecture\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.hidden = nn.Linear(28*28, 128)\n","        self.relu = nn.ReLU()\n","        self.output = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.hidden(x)\n","        x = self.relu(x)\n","        x = self.output(x)\n","        return x\n","\n","# Set up data loaders\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","\n","# Initialize the model, loss function, and optimizer\n","model = SimpleNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Custom training loop\n","def train(model, dataloader, criterion, optimizer, epochs):\n","    model.train()\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for images, labels in dataloader:\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","        print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')\n","\n","# Train the model\n","train(model, train_loader, criterion, optimizer, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uV-MG1uElHXT","executionInfo":{"status":"ok","timestamp":1715094283610,"user_tz":300,"elapsed":91877,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"fe3f1190-d455-455c-8f44-2891f90e8853"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 21516991.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 631210.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 5668740.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 3384955.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Epoch 1, Loss: 0.3874411182696504\n","Epoch 2, Loss: 0.19976051347548646\n","Epoch 3, Loss: 0.14357210623263233\n","Epoch 4, Loss: 0.11548272613733848\n","Epoch 5, Loss: 0.09890914866144755\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, regularizers\n","import numpy as np\n","\n","# Load and preprocess the MNIST dataset\n","mnist = keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Define the model architecture with L2 regularization\n","l2_reg = regularizers.l2(0.05)\n","model = keras.models.Sequential([\n","    layers.Flatten(input_shape=(28, 28)),\n","    layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg),\n","    layers.Dense(10, kernel_regularizer=l2_reg)\n","])\n","\n","# Custom function to generate random batches\n","def random_batch(X, y, batch_size=32):\n","    idx = np.random.randint(len(X), size=batch_size)\n","    return X[idx], y[idx]\n","\n","# Custom function to print training progress\n","def print_status_bar(iteration, total, loss, metrics=None):\n","    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n","    end = \"\" if iteration < total else \"\\n\"\n","    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)\n","\n","# Training parameters\n","n_epochs = 5\n","batch_size = 32\n","n_steps = len(X_train) // batch_size\n","optimizer = keras.optimizers.Nadam(lr=0.01)\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","mean_loss = keras.metrics.Mean()\n","metrics = [keras.metrics.SparseCategoricalAccuracy()]\n","\n","# Training loop\n","for epoch in range(1, n_epochs + 1):\n","    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n","    for step in range(1, n_steps + 1):\n","        X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n","        with tf.GradientTape() as tape:\n","            y_pred = model(X_batch, training=True)\n","            main_loss = loss_fn(y_batch, y_pred)\n","            loss = tf.add_n([main_loss] + model.losses)\n","\n","        gradients = tape.gradient(loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","        mean_loss(loss)\n","        for metric in metrics:\n","            metric(y_batch, y_pred)\n","\n","        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n","\n","    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n","    for metric in [mean_loss] + metrics:\n","        metric.reset_states()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9lupRjUljyw","executionInfo":{"status":"ok","timestamp":1715094597501,"user_tz":300,"elapsed":288817,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"19d4a49c-9ed0-491e-d266-0fc441f24847"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","60000/60000 - mean: 1.6276 - sparse_categorical_accuracy: 0.8329\n","60000/60000 - mean: 1.6276 - sparse_categorical_accuracy: 0.8329\n","Epoch 2/5\n","60000/60000 - mean: 1.4766 - sparse_categorical_accuracy: 0.8418\n","60000/60000 - mean: 1.4766 - sparse_categorical_accuracy: 0.8418\n","Epoch 3/5\n","60000/60000 - mean: 1.4739 - sparse_categorical_accuracy: 0.8399\n","60000/60000 - mean: 1.4739 - sparse_categorical_accuracy: 0.8399\n","Epoch 4/5\n","60000/60000 - mean: 1.4678 - sparse_categorical_accuracy: 0.8386\n","60000/60000 - mean: 1.4678 - sparse_categorical_accuracy: 0.8386\n","Epoch 5/5\n","60000/60000 - mean: 1.4706 - sparse_categorical_accuracy: 0.8383\n","60000/60000 - mean: 1.4706 - sparse_categorical_accuracy: 0.8383\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, regularizers\n","import numpy as np\n","\n","# Load and preprocess the MNIST dataset\n","mnist = keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Define the model architecture with L2 regularization\n","l2_reg = regularizers.l2(0.05)\n","model = keras.models.Sequential([\n","    layers.Flatten(input_shape=(28, 28)),\n","    layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg),\n","    layers.Dense(10, kernel_regularizer=l2_reg)\n","])\n","\n","# Custom function to generate random batches\n","def random_batch(X, y, batch_size=32):\n","    idx = np.random.randint(len(X), size=batch_size)\n","    return X[idx], y[idx]\n","\n","# Custom function to print training progress\n","def print_status_bar(iteration, total, loss, metrics=None):\n","    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n","    end = \"\" if iteration < total else \"\\n\"\n","    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)\n","\n","# Training parameters\n","n_epochs = 5\n","batch_size = 32\n","n_steps = len(X_train) // batch_size\n","optimizer = keras.optimizers.Nadam(lr=0.01)\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","mean_loss = keras.metrics.Mean()\n","metrics = [keras.metrics.SparseCategoricalAccuracy()]\n","\n","# Training loop\n","for epoch in range(1, n_epochs + 1):\n","    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n","    for step in range(1, n_steps + 1):\n","        X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n","        with tf.GradientTape() as tape:\n","            y_pred = model(X_batch, training=True)\n","            main_loss = loss_fn(y_batch, y_pred)\n","            loss = tf.add_n([main_loss] + model.losses)\n","\n","        gradients = tape.gradient(loss, model.trainable_variables)\n","\n","        # Apply weight constraints if defined\n","        for variable in model.variables:\n","            if variable.constraint is not None:\n","                variable.assign(variable.constraint(variable))\n","\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","        mean_loss(loss)\n","        for metric in metrics:\n","            metric(y_batch, y_pred)\n","\n","        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n","\n","    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n","    for metric in [mean_loss] + metrics:\n","        metric.reset_states()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLjUEDaQmv3o","executionInfo":{"status":"ok","timestamp":1715094925683,"user_tz":300,"elapsed":305590,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"3352b987-4930-43b2-a783-3be1934d3fd9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","60000/60000 - mean: 1.6318 - sparse_categorical_accuracy: 0.8331\n","60000/60000 - mean: 1.6318 - sparse_categorical_accuracy: 0.8331\n","Epoch 2/5\n","60000/60000 - mean: 1.4822 - sparse_categorical_accuracy: 0.8392\n","60000/60000 - mean: 1.4822 - sparse_categorical_accuracy: 0.8392\n","Epoch 3/5\n","60000/60000 - mean: 1.4721 - sparse_categorical_accuracy: 0.8381\n","60000/60000 - mean: 1.4721 - sparse_categorical_accuracy: 0.8381\n","Epoch 4/5\n","60000/60000 - mean: 1.4745 - sparse_categorical_accuracy: 0.8393\n","60000/60000 - mean: 1.4745 - sparse_categorical_accuracy: 0.8393\n","Epoch 5/5\n","60000/60000 - mean: 1.4733 - sparse_categorical_accuracy: 0.8359\n","60000/60000 - mean: 1.4733 - sparse_categorical_accuracy: 0.8359\n"]}]},{"cell_type":"markdown","source":["# TensorFlow Functions and Graphs\n"],"metadata":{"id":"oAC92H1WmMCE"}},{"cell_type":"code","source":["def cube(x):\n","   return x ** 3"],"metadata":{"id":"4SesrbulmOh7","executionInfo":{"status":"ok","timestamp":1715094929057,"user_tz":300,"elapsed":376,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["cube(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FW-eJCGZmR8y","executionInfo":{"status":"ok","timestamp":1715094930311,"user_tz":300,"elapsed":5,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"593feb96-85b0-4365-88b4-aa42b14e0073"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["cube(tf.constant(2.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Dw0jRS6mTah","executionInfo":{"status":"ok","timestamp":1715094931409,"user_tz":300,"elapsed":4,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"98873e38-529b-45b2-953a-128b2d322d81"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["tf_cube = tf.function(cube)\n","tf_cube"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdfcpMdWmU6e","executionInfo":{"status":"ok","timestamp":1715094932723,"user_tz":300,"elapsed":7,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"1b4bb248-6e95-44bc-9b48-b0abf48eb18e"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x7ca65af08760>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["tf_cube(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBYkpOWmm-15","executionInfo":{"status":"ok","timestamp":1715094934224,"user_tz":300,"elapsed":292,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"db71e005-af80-47f6-e115-ee6463cc5986"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=int32, numpy=8>"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["tf_cube(tf.constant(2.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"875alw5InAvJ","executionInfo":{"status":"ok","timestamp":1715094935628,"user_tz":300,"elapsed":6,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"437960e8-d1a8-4bc4-a39a-1558f1ad0e0e"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["@tf.function\n","def tf_cube(x):\n","  return x ** 3"],"metadata":{"id":"YPF2UyvonCsT","executionInfo":{"status":"ok","timestamp":1715094939911,"user_tz":300,"elapsed":442,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["tf_cube.python_function(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bS5G6AA8nD23","executionInfo":{"status":"ok","timestamp":1715094942244,"user_tz":300,"elapsed":292,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"1f072295-fd4e-47e9-da1b-a17c487a39cf"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Autograph and Tracing and TF Function Rules\n"],"metadata":{"id":"p5Jaa1PQnJTA"}},{"cell_type":"code","source":["tf.autograph.to_code(tf_cube.python_function)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"rRlKjqenn5_q","executionInfo":{"status":"ok","timestamp":1715094968488,"user_tz":300,"elapsed":13,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"592412c8-15d9-45ef-a1e5-8f93faa74ca6"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"def tf__tf_cube(x):\\n    with ag__.FunctionScope('tf_cube', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\\n        do_return = False\\n        retval_ = ag__.UndefinedReturnValue()\\n        try:\\n            do_return = True\\n            retval_ = ag__.ld(x) ** 3\\n        except:\\n            do_return = False\\n            raise\\n        return fscope.ret(retval_, do_return)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def compute_jacobian(func, x):\n","    \"\"\"\n","    Compute the Jacobian matrix of a function `func` at point `x` using TensorFlow.\n","\n","    Args:\n","        func: A callable function that takes a TensorFlow tensor `x` as input.\n","        x: A TensorFlow tensor representing the point at which to compute the Jacobian.\n","\n","    Returns:\n","        jacobian: A TensorFlow tensor representing the Jacobian matrix.\n","    \"\"\"\n","    with tf.GradientTape() as tape:\n","        tape.watch(x)\n","        y = func(x)\n","    jacobian = tape.jacobian(y, x)\n","    return jacobian\n","\n","def compute_hessian(func, x):\n","    \"\"\"\n","    Compute the Hessian matrix of a function `func` at point `x` using TensorFlow.\n","\n","    Args:\n","        func: A callable function that takes a TensorFlow tensor `x` as input.\n","        x: A TensorFlow tensor representing the point at which to compute the Hessian.\n","\n","    Returns:\n","        hessian: A TensorFlow tensor representing the Hessian matrix.\n","    \"\"\"\n","    with tf.GradientTape() as tape2:\n","        tape2.watch(x)\n","        with tf.GradientTape() as tape1:\n","            tape1.watch(x)\n","            y = func(x)\n","        gradients = tape1.gradient(y, x)\n","    hessian = tape2.jacobian(gradients, x)\n","    return hessian\n","\n","# Example usage:\n","# Define a function for which to compute Jacobian and Hessian\n","def quadratic_function(x):\n","    return tf.reduce_sum(x**2)\n","\n","# Define the point at which to compute Jacobian and Hessian\n","x_value = tf.constant([1.0, 2.0])\n","\n","# Compute Jacobian\n","jacobian_result = compute_jacobian(quadratic_function, x_value)\n","print(\"Jacobian:\")\n","print(jacobian_result)\n","\n","# Compute Hessian\n","hessian_result = compute_hessian(quadratic_function, x_value)\n","print(\"\\nHessian:\")\n","print(hessian_result)\n","\n","# Convert functions to autograph-compatible code\n","jacobian_code = tf.autograph.to_code(compute_jacobian)\n","hessian_code = tf.autograph.to_code(compute_hessian)\n","\n","print(\"\\nAutograph-compatible code for compute_jacobian:\")\n","print(jacobian_code)\n","\n","print(\"\\nAutograph-compatible code for compute_hessian:\")\n","print(hessian_code)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQB0oXTpoS0u","executionInfo":{"status":"ok","timestamp":1715095217309,"user_tz":300,"elapsed":822,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"bf22f253-19b4-4339-d6c8-2974d07522f8"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Jacobian:\n","tf.Tensor([2. 4.], shape=(2,), dtype=float32)\n","\n","Hessian:\n","tf.Tensor(\n","[[2. 0.]\n"," [0. 2.]], shape=(2, 2), dtype=float32)\n","\n","Autograph-compatible code for compute_jacobian:\n","    def tf__compute_jacobian(func, x):\n","        \"\"\"\n","Compute the Jacobian matrix of a function `func` at point `x` using TensorFlow.\n","\n","Args:\n","    func: A callable function that takes a TensorFlow tensor `x` as input.\n","    x: A TensorFlow tensor representing the point at which to compute the Jacobian.\n","\n","Returns:\n","    jacobian: A TensorFlow tensor representing the Jacobian matrix.\n","\"\"\"\n","        with ag__.FunctionScope('compute_jacobian', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n","            do_return = False\n","            retval_ = ag__.UndefinedReturnValue()\n","            with ag__.ld(tf).GradientTape() as tape:\n","                ag__.converted_call(ag__.ld(tape).watch, (ag__.ld(x),), None, fscope)\n","                y = ag__.converted_call(ag__.ld(func), (ag__.ld(x),), None, fscope)\n","            jacobian = ag__.converted_call(ag__.ld(tape).jacobian, (ag__.ld(y), ag__.ld(x)), None, fscope)\n","            try:\n","                do_return = True\n","                retval_ = ag__.ld(jacobian)\n","            except:\n","                do_return = False\n","                raise\n","            return fscope.ret(retval_, do_return)\n","\n","\n","Autograph-compatible code for compute_hessian:\n","    def tf__compute_hessian(func, x):\n","        \"\"\"\n","Compute the Hessian matrix of a function `func` at point `x` using TensorFlow.\n","\n","Args:\n","    func: A callable function that takes a TensorFlow tensor `x` as input.\n","    x: A TensorFlow tensor representing the point at which to compute the Hessian.\n","\n","Returns:\n","    hessian: A TensorFlow tensor representing the Hessian matrix.\n","\"\"\"\n","        with ag__.FunctionScope('compute_hessian', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n","            do_return = False\n","            retval_ = ag__.UndefinedReturnValue()\n","            with ag__.ld(tf).GradientTape() as tape2:\n","                ag__.converted_call(ag__.ld(tape2).watch, (ag__.ld(x),), None, fscope)\n","                with ag__.ld(tf).GradientTape() as tape1:\n","                    ag__.converted_call(ag__.ld(tape1).watch, (ag__.ld(x),), None, fscope)\n","                    y = ag__.converted_call(ag__.ld(func), (ag__.ld(x),), None, fscope)\n","                gradients = ag__.converted_call(ag__.ld(tape1).gradient, (ag__.ld(y), ag__.ld(x)), None, fscope)\n","            hessian = ag__.converted_call(ag__.ld(tape2).jacobian, (ag__.ld(gradients), ag__.ld(x)), None, fscope)\n","            try:\n","                do_return = True\n","                retval_ = ag__.ld(hessian)\n","            except:\n","                do_return = False\n","                raise\n","            return fscope.ret(retval_, do_return)\n","\n"]}]},{"cell_type":"markdown","source":["#Loading and Preprocessing Data with TensorFlow"],"metadata":{"id":"LGl3nNr4pJrc"}},{"cell_type":"markdown","source":["# The Data API"],"metadata":{"id":"Dq3RNiigpMQb"}},{"cell_type":"code","source":["X = tf.range(10)"],"metadata":{"id":"PTE-k0QPpLIU","executionInfo":{"status":"ok","timestamp":1715095269965,"user_tz":300,"elapsed":310,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices(X)"],"metadata":{"id":"o-g_sJCTpPa0","executionInfo":{"status":"ok","timestamp":1715095280096,"user_tz":300,"elapsed":2,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uitxzEsZpR11","executionInfo":{"status":"ok","timestamp":1715095286353,"user_tz":300,"elapsed":9,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"27465220-c309-4961-8aae-38b6f8aba78e"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["for item in dataset:\n","  print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvGElxJKpTcN","executionInfo":{"status":"ok","timestamp":1715096210648,"user_tz":300,"elapsed":405,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"bf444168-c15f-49f7-8a47-d3f26913ae00"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(0, shape=(), dtype=int32)\n","tf.Tensor(1, shape=(), dtype=int32)\n","tf.Tensor(2, shape=(), dtype=int32)\n","tf.Tensor(3, shape=(), dtype=int32)\n","tf.Tensor(4, shape=(), dtype=int32)\n","tf.Tensor(5, shape=(), dtype=int32)\n","tf.Tensor(6, shape=(), dtype=int32)\n","tf.Tensor(7, shape=(), dtype=int32)\n","tf.Tensor(8, shape=(), dtype=int32)\n","tf.Tensor(9, shape=(), dtype=int32)\n"]}]},{"cell_type":"markdown","source":["# Chaining Transformations"],"metadata":{"id":"k_y-db7YtKj-"}},{"cell_type":"code","source":["dataset = dataset.repeat(3).batch(7)\n","for item in dataset:\n","  print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4FmaENCtLQf","executionInfo":{"status":"ok","timestamp":1715096350916,"user_tz":300,"elapsed":315,"user":{"displayName":"Wilfredo Aaron Sosa Ramos","userId":"09390934792605274189"}},"outputId":"e314082d-4404-44c7-856a-8b53f9602448"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n","tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n","tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n","tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n","tf.Tensor([8 9], shape=(2,), dtype=int32)\n"]}]}]}