# -*- coding: utf-8 -*-
"""CB001 - Chapter 14.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mNnYijLteU6ewGUd-eADnTLCJM1Rq1A0

#SVM for Regression
"""

#Mount the google drive connection to our dataset
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/AI/datasets/housing.csv')

df.head()

df.drop("Unnamed: 0", axis=1, inplace=True)

df.info()

df.head()

df.isnull().sum()

df.isna().sum()

X = df.drop("MedHouseVal", axis=1)
y = df["MedHouseVal"]

"""Visualize the data"""

import matplotlib.pyplot as plt
import seaborn as sns

def plot_charts(df):
  # Numeric features
  numeric_features = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]
  for feature in numeric_features:
      plt.figure(figsize=(8, 6))
      sns.histplot(df[feature], kde=True, color='blue')
      plt.title(f'Distribution of {feature}')
      plt.xlabel(feature)
      plt.ylabel('Frequency')
      plt.show()

plot_charts(df)

from sklearn.model_selection import train_test_split

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVR

standard_scaler = StandardScaler()

from sklearn.metrics import mean_squared_error, mean_absolute_error

def Performance(model):
    global X_train, y_train, X_val, y_val, X_test, y_test

    # Model evaluation on validation set
    y_val_pred = model.predict(X_val)
    rmse_val = mean_squared_error(y_val, y_val_pred, squared=False)
    mae_val = mean_absolute_error(y_val, y_val_pred)

    print("Validation set metrics:")
    print(f"RMSE: {rmse_val:.4f}")
    print(f"MAE: {mae_val:.4f}")

    # Model evaluation on test set
    y_test_pred = model.predict(X_test)
    rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)
    mae_test = mean_absolute_error(y_test, y_test_pred)

    print("\nTest set metrics:")
    print(f"RMSE: {rmse_test:.4f}")
    print(f"MAE: {mae_test:.4f}")

from sklearn.model_selection import cross_val_score
def CrossValidationScore(model_list):
    global X_scaled,y_encoded

    mean_cross_val_score = []
    model_name           = []

    for model in model_list:
        model_name.append(type(model).__name__)

    for i in model_list:
        scores = cross_val_score(i, X_scaled, y_encoded, cv=5)
        mean_cross_val_score.append(scores.mean())

    cvs = pd.DataFrame({"Model Name":model_name,"CVS":mean_cross_val_score})
    return cvs.style.background_gradient("Greens")

"""#Lineal SVR"""

from sklearn.svm import LinearSVR

start_time = time.time()
lineal_svm_reg = LinearSVR(epsilon=1.5)
lineal_svr_pipeline = Pipeline(steps=[
    ('scaler', standard_scaler),
    ('regressor', lineal_svm_reg)
])
lineal_svr_pipeline.fit(X_train,y_train)
end_time = time.time()
training_time = end_time - start_time
print("The training time is: ",training_time)

Performance(lineal_svr_pipeline.named_steps['regressor'])

"""#SVR"""

import time

start_time = time.time()
svm_reg = SVR(C=100, epsilon=0.1)
svr_pipeline = Pipeline(steps=[
    ('scaler', standard_scaler),
    ('regressor', svm_reg)
])
svr_pipeline.fit(X_train,y_train)
end_time = time.time()
training_time = end_time - start_time
print("The training time is: ",training_time)

Performance(svr_pipeline.named_steps['regressor'])

X_scaled = svr_pipeline.named_steps['scaler'].transform(X)
y_encoded = y

"""#SVR (Degree = 2)"""

start_time = time.time()
svm_poly_reg = SVR(kernel="poly", degree=2, C=100, epsilon=0.1)
svr_poly_pipeline = Pipeline(steps=[
    ('scaler', standard_scaler),
    ('regressor', svm_poly_reg)
])
svr_poly_pipeline.fit(X_train,y_train)
end_time = time.time()
training_time = end_time - start_time
print("The training time is: ",training_time)

Performance(svr_poly_pipeline.named_steps['regressor'])