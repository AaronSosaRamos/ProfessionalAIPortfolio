{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Momentum Optimization"
      ],
      "metadata": {
        "id": "AO0u9gwJZ3qn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFruZngpVjpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed80351e-3ca2-488a-844c-6850f9dbb08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 9s 5ms/step - loss: 0.3433 - accuracy: 0.9008 - val_loss: 0.1979 - val_accuracy: 0.9420\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1618 - accuracy: 0.9525 - val_loss: 0.1393 - val_accuracy: 0.9607\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1150 - accuracy: 0.9670 - val_loss: 0.1154 - val_accuracy: 0.9675\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9738 - val_loss: 0.1032 - val_accuracy: 0.9707\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0743 - accuracy: 0.9782 - val_loss: 0.0989 - val_accuracy: 0.9709\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0624 - accuracy: 0.9822 - val_loss: 0.0974 - val_accuracy: 0.9721\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0533 - accuracy: 0.9851 - val_loss: 0.0906 - val_accuracy: 0.9740\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0451 - accuracy: 0.9874 - val_loss: 0.0896 - val_accuracy: 0.9735\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0388 - accuracy: 0.9898 - val_loss: 0.0903 - val_accuracy: 0.9745\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0340 - accuracy: 0.9911 - val_loss: 0.0868 - val_accuracy: 0.9742\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0782 - accuracy: 0.9755\n",
            "Test Accuracy: 0.9754999876022339\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define the optimizer with momentum\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "\n",
        "# Step 4: Compile the model with the specified optimizer\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Nesterov Accelerated Gradient"
      ],
      "metadata": {
        "id": "u5_qzcCtdUCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define the optimizer with Nesterov Accelerated Gradient\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Step 4: Compile the model with the specified optimizer\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6TiLhlMdUn3",
        "outputId": "5e9ad336-bafc-454f-a14e-edf045ce4b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3330 - accuracy: 0.9042 - val_loss: 0.1898 - val_accuracy: 0.9479\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1623 - accuracy: 0.9526 - val_loss: 0.1414 - val_accuracy: 0.9605\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1164 - accuracy: 0.9658 - val_loss: 0.1166 - val_accuracy: 0.9661\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9737 - val_loss: 0.0989 - val_accuracy: 0.9711\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9782 - val_loss: 0.0972 - val_accuracy: 0.9722\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0623 - accuracy: 0.9827 - val_loss: 0.0912 - val_accuracy: 0.9723\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0531 - accuracy: 0.9855 - val_loss: 0.0860 - val_accuracy: 0.9742\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.0866 - val_accuracy: 0.9745\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 0.0833 - val_accuracy: 0.9763\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0334 - accuracy: 0.9911 - val_loss: 0.0870 - val_accuracy: 0.9759\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9766\n",
            "Test Accuracy: 0.9765999913215637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AdaGrad"
      ],
      "metadata": {
        "id": "BchoZCetdaF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define the optimizer with AdaGrad\n",
        "optimizer = Adagrad(learning_rate=0.01)\n",
        "\n",
        "# Step 4: Compile the model with the specified optimizer\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prl9zObKdahf",
        "outputId": "22af7ca8-49d1-466f-b03b-58e15063715b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4891 - accuracy: 0.8700 - val_loss: 0.2901 - val_accuracy: 0.9203\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2765 - accuracy: 0.9227 - val_loss: 0.2379 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2315 - accuracy: 0.9359 - val_loss: 0.2111 - val_accuracy: 0.9425\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2030 - accuracy: 0.9435 - val_loss: 0.1888 - val_accuracy: 0.9488\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1828 - accuracy: 0.9492 - val_loss: 0.1754 - val_accuracy: 0.9523\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1671 - accuracy: 0.9534 - val_loss: 0.1654 - val_accuracy: 0.9542\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1548 - accuracy: 0.9569 - val_loss: 0.1565 - val_accuracy: 0.9563\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1447 - accuracy: 0.9595 - val_loss: 0.1505 - val_accuracy: 0.9588\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1362 - accuracy: 0.9619 - val_loss: 0.1453 - val_accuracy: 0.9596\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1291 - accuracy: 0.9639 - val_loss: 0.1383 - val_accuracy: 0.9612\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1344 - accuracy: 0.9614\n",
            "Test Accuracy: 0.9613999724388123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RMSProp"
      ],
      "metadata": {
        "id": "Kd6vj66Zdydu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define the optimizer with RMSProp\n",
        "optimizer = RMSprop(learning_rate=0.001)\n",
        "\n",
        "# Step 4: Compile the model with the specified optimizer\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qumsmgedy6n",
        "outputId": "668cbe57-9702-4cf8-eecb-16de705e924f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2880 - accuracy: 0.9158 - val_loss: 0.1581 - val_accuracy: 0.9538\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1340 - accuracy: 0.9598 - val_loss: 0.1176 - val_accuracy: 0.9664\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0947 - accuracy: 0.9723 - val_loss: 0.1278 - val_accuracy: 0.9629\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0725 - accuracy: 0.9792 - val_loss: 0.1115 - val_accuracy: 0.9682\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0604 - accuracy: 0.9825 - val_loss: 0.0970 - val_accuracy: 0.9726\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0504 - accuracy: 0.9851 - val_loss: 0.0968 - val_accuracy: 0.9737\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.1070 - val_accuracy: 0.9731\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.1070 - val_accuracy: 0.9731\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.1057 - val_accuracy: 0.9733\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0268 - accuracy: 0.9924 - val_loss: 0.1062 - val_accuracy: 0.9736\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9748\n",
            "Test Accuracy: 0.9747999906539917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adam and Nadam Optimization"
      ],
      "metadata": {
        "id": "50a831AZeLVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define the optimizer with Adam\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Step 4: Compile the model with the specified optimizer\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCD2cQ3xeLxo",
        "outputId": "5c6886cc-b3c9-4f93-94c0-8b5ebb87bbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 8s 4ms/step - loss: 0.2887 - accuracy: 0.9169 - val_loss: 0.1676 - val_accuracy: 0.9517\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1268 - accuracy: 0.9623 - val_loss: 0.1091 - val_accuracy: 0.9672\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0849 - accuracy: 0.9752 - val_loss: 0.1135 - val_accuracy: 0.9670\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0643 - accuracy: 0.9804 - val_loss: 0.0926 - val_accuracy: 0.9727\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.0869 - val_accuracy: 0.9739\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.0916 - val_accuracy: 0.9731\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.0912 - val_accuracy: 0.9738\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0803 - val_accuracy: 0.9787\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0871 - val_accuracy: 0.9765\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0975 - val_accuracy: 0.9753\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9757\n",
            "Test Accuracy: 0.9757000207901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define the optimizer with Nadam\n",
        "optimizer = Nadam(learning_rate=0.001)\n",
        "\n",
        "# Step 4: Compile the model with the specified optimizer\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiUWcuNFeSGO",
        "outputId": "c6d962f5-7fe5-4b37-8126-753f9184bc44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2873 - accuracy: 0.9179 - val_loss: 0.1532 - val_accuracy: 0.9579\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1262 - accuracy: 0.9627 - val_loss: 0.1186 - val_accuracy: 0.9651\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0863 - accuracy: 0.9741 - val_loss: 0.1004 - val_accuracy: 0.9716\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 0.0930 - val_accuracy: 0.9722\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0485 - accuracy: 0.9855 - val_loss: 0.0902 - val_accuracy: 0.9731\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 0.0862 - val_accuracy: 0.9772\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.0852 - val_accuracy: 0.9758\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.0934 - val_accuracy: 0.9742\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0995 - val_accuracy: 0.9719\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.1012 - val_accuracy: 0.9747\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9783\n",
            "Test Accuracy: 0.9782999753952026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adamax"
      ],
      "metadata": {
        "id": "40jKTIdqeaka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define the optimizer with Adamax\n",
        "optimizer = Adamax(learning_rate=0.001)\n",
        "\n",
        "# Step 4: Compile the model with the specified optimizer\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_bfRVtVeZvQ",
        "outputId": "aaaa8fda-939b-4cc1-9dc8-4389b56c3e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4046 - accuracy: 0.8926 - val_loss: 0.2471 - val_accuracy: 0.9302\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2218 - accuracy: 0.9375 - val_loss: 0.1889 - val_accuracy: 0.9492\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1755 - accuracy: 0.9508 - val_loss: 0.1666 - val_accuracy: 0.9537\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1466 - accuracy: 0.9591 - val_loss: 0.1446 - val_accuracy: 0.9592\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1261 - accuracy: 0.9653 - val_loss: 0.1347 - val_accuracy: 0.9628\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1112 - accuracy: 0.9696 - val_loss: 0.1279 - val_accuracy: 0.9647\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0988 - accuracy: 0.9729 - val_loss: 0.1177 - val_accuracy: 0.9650\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0893 - accuracy: 0.9754 - val_loss: 0.1092 - val_accuracy: 0.9678\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0810 - accuracy: 0.9776 - val_loss: 0.1065 - val_accuracy: 0.9688\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0742 - accuracy: 0.9800 - val_loss: 0.1029 - val_accuracy: 0.9696\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9725\n",
            "Test Accuracy: 0.9725000262260437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate Scheduling\n"
      ],
      "metadata": {
        "id": "t_oxgSpxetkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Power scheduling\n"
      ],
      "metadata": {
        "id": "oUEyN5sfexfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYQAAAA4CAYAAAD9wo9pAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABSlSURBVHhe7Z0PUFRHnse/2bXOyWYRUl6JVVcuniExf9BJsopVIYErIGazDliRQ1PCzd6ZyK5BcmfAug1I1kBSG8FU6aA5AS3DyJWbIYnFkIrLRF2G3WNrxorOw1qOMaXHGM3OeFqZycrNWHGrr/vNG5i/MDCAGn6fqse819Pd7/Wv+/Wv+9e/Hu5hHBAEQRCznu8pnwRBEMQshxQCQRAEIUMKgSAIgpAhhUAQBEHIkEIgCIIgZEghEARBEDKkEAiCIAgZUggEQRCEDCkEgiAIQoYUAkEQBCFDCoEgCIKQIYVAEARByJBCIAiCIGRIIRAEQRAypBAIgiAIGVIIBEEQhAwpBIIgCEKGFAJBEAQhQwqBIAiCkCGFQBDE7GLYA49POSdCIIVAEMQswAfXWRM69lbhH7PKYbquBBMhkEIgCGIWoELyklUoKF+PVReVICKCmVUIPg98t5TzsYg3HkEQRJyokpOhmqNcEFGZkELweRKwvV0yoeZNE1zxVMhf7Wgqa4R1WLkm4iaROkqofgmCuOuJSyG4jm/FsnnzsGDRIpR3uZTQCeCT0PiKCTlVxUhTgsbkvkxs35EK3bYOOJSg24HjVCOqXtNDmqRi8vXrefpGmC8pAXEwmTSCROoo4fqdQSYrH4IgxicuhZD6/D6c+/OHKFOuJ4p0qBKWFyuwer4SEIKElp8VoP4zj3KtsESL7Y/tRU3H7eqgXLC21aPl4FaYBpSgCdLPO9qWg/VotYSXwQNruymqsoudZmwSqaNE63cmmax87nQ8p/UwkW2buM3EbzK6LwWpyumEuG5E6+sPQ/t8jLlBfy/0x75GSmqyEjCKuqAMvuoWmG+LGSMVBTXt2P3eCZStVIImSObLJ7CvsR21Pw2X3BAsBySuciKJnSYOJltHgkTSziAJyecOZsjaAok8X4jbzLQvKrtOGaB/uRA5UWcHgGPAgn7kYPlDSkAwS3JQ+GgjTH23x7CteqgQZaWZiFRVcTI/E9qfF2Lpfcp1gIsSzP3KeTix0hB+vpPycUA6FatBTB6PK2zWHY5YMyLnDSKIBBSCj7cnD1znrTCfdcF3ywP7aTOkK8GdtwfSH40ozFwa0anKC5geB6y9RuDFx7H4Jr+OsNWnQZ2diqY/Tv3LMi5i8wp/PqnXDPvIyC2szCLkup2XwQzr+bCXzyfSuyJl4pHQ9Ho9TDy1W5YBPwJfx0ojkO9jhL65A6bT9pl9kV0STB0t0Hfx54oyrfEIeXTp0dJhipQDR65rl3h+PivixZLj9/vlNxUylfO/xJVsL5eLCBj219voPSLxyfFH7+E63YGWvXpY4x6lx9P+OePWG39H9lei/jOeo1uUTxyRT+25aIWxvQUdn1nhiBRxFHj7+qwGW4/FWIW7bkb9qy2w31Suv/MIM20Tmmp10MMC/a56NO2NbradzUxeIXj6oX+9FJo1+SjY3SIL2tLXimce0aBppP+2QzoIqB8IMxcNS+h6Xw/9njrsbQeWYxBGcc1f6HAW/mgVMOCY8Ypz9DagZp0Gz2gKYAzYduUyFyF/BS/znk507a1Ca58TXlxF95ZFyN9lHemAPOc+QH2ZBpq8AjT2KW+wxwr9+71w3BK9Ku9kRZn50XnO/33UNIL+JuT/fSk6h1dh7YvZSB1qRdGKrTBO+8KqD/b2rVj5qglzV23Ac2lXcWTjspBORtqfj0UbO3HzybXYwJW3o7UIy14xBtWXB/3tNShdq0G+ppF3ujXQ9VnQ+vSD0OyXEpcpv5PpzZeQn/cMCjQGmI7VoOaYHW7chH3f01hWFu6YwONvz4emSeIxAGfXS1j5eD4anWlQndkK3ak41ybiaf/j1pvopPTovSBWrLgsj/vbg76r36/YZDwwv12A0v9wIO3ZDcica0ZlDi//6ViqLoAKaaW7sfkrrhQ6wt4eoQxes+K597Yjc9bMRJORWVqBivp2nPvmC3TpalHxr6vjc3KZTbC4sbCGpCRWYnAq134s7ySxpCQNa7Yz5j2jYyWFlazzsvLlZQMr4d+1XVCuw5F0LCspi+kk5Toa1gaefwO/+9h4T9YxTaFmAkcd67mhJI6FQzx/EmuwKtcKlrdEmUOfe+hoCQ+rZN1uJUDGwupiyixWmSLTeM11LJ2Hbfo4EOZmnVt4HloDC8s5ah3FR2RaL5d9VlJRSP25jeUsKT1QTi/r2ZnOy7KJdQaSXetk5dGeQa7HJKZpHeTJbEyn1bBK42icRGXqj5vEyo1BkfvqIvKUnz+pmvV4lQAlv7wD4rm8vEQTY6z2H3e9KbIJb2cCp4GXK5231aAHs+3JYkm5zYw/cRx4mW1fCSs3DPkvr/WwOi1ve+O1fWJWMkVrCNl4/CE+JnmiAu2du1H4d0qwTDLunauchjHm+kEIbnjHGRCpcmvR1dk1gaMWOeONjr6vfIYj9lIs34Ds5f5LgUqO64Tnhnw5gkr5nAjhaVTZtTj35VUceiGwkJqMhWJoc2xoGmdOHvQerUf/8hyolyhBnGR1DgpdLZDOiysVcmrO4cs/H0Jh4NHmL5RHXcaL0Z8sW72UJ1Ojoq0LuwuCFoYTlKk/bhkKs4OMk3NEzH74gswi9gE9/5uCe4MyEafWz+1wqVSTqq9Y7T/xepNg2GsEClbh8aAHU2c+B5zuRf8VJWBMVFCXH8Tmq3ym0KyfhTMDYiJM+6JybDywW3ljfzknpLFHh3cKQRaUO4IHFmKhcjoTqHwW6Gu3omBtAbbWNsFgVb6YNvzmPsAG494mNAWOY06sqn8b6oCTAO90fZ/rUfNKAX+2rajZa4BF+WrCJCzTVKSM4wGwdHkZjyXBEdSZirHG6mz1tHhZJVRvV87DIsxPDhP0wXVgTcHb9auR9kN/tPHhSqFgPXCkHvZn109KGcybN4+OO/SYUpSZQhyMYTKKMF0oyCajEmYImJBC8E/VNYeVqWws4jQZsW+9zO12T+gY1zwgP38Uk1GUMstT+4iyjmVmC5TJzQbPOIOeJTKN01TJ8pLyWKVxVFbRzU5TaTKyMV0Wv0dhG4tdQ07WXZXHknIrWadDCVLySXonrMbkeozVFpTyJCBTf9wweUQ1xdhYQ24Gy9PqWKe5kzVvyWN5Vd1jlHFsxmr/cddb2HO67TbmFA3C3c0qhSx39EzYlBWCg+cjm4m8bPBw+aj5aNIMMdufQux4s56hMxb+Jt/9TO8MYf4CpPHx4tBV5TqYfgu6+ZgsW60s61zko8zfRC7o+f7iFgM/xLA6jeJxwCbZJnAM3SE/02CHcU9v0CJiOBIMb7bAWvoqaguiLYFJaGmWlPOpRI3s4uXA7+wYCpfTJcnvM99vQF2zFdp/q0Xhj/xfhXC2BS1nlfM7hdMmSL84gRPNWuSoc7Dh15/gRON0LC5Ovt7sxxrRK+SbvArZpfyz3xGxZ8V3ns9y4mm/l0yoqpWwXjYTqbD0n3ejYrgxcqE5bhzoeN2Am2kRfoPwXJ+CF+qiyT8LOmiOuk/nTiXtIUC/f9QB4m5lahRC3xCcymkIqhQsXO6CyxnZ3XmuONAPPn19RFzxRtbqwtpgm7KC6ypvuAVqLFauYzJ/KXKycyZwqJE6OYMxIFwH+THZyk9NzeF/lXURnxe+JQsi3HIjGL4ZdD8JFpNy6nPD4Z4e30F16RsoS+UvZ3uw95cP5sNGuINk5/YFSUJW9H58XzvC3CxjDA4ECcrU91f5r3w+JnP4UxxoQYc1MDCwwMw73IQGB7HavyCeepufCrlF/EXE9PF2sRQLZJNcMgp/8TYyf1ePlpCd/A4YWrkyGa/9it8P2xlQBkoYT5SIUnBxZTX4fMVIfr4rwiW5CVVFK1F+ahy7bkhbiMGS1dj8lA8f/D5WQ7lTcMH4Wj1MgSLflwntEgN2HA8EeGAXrs8DvP/rD3OBvuWCdNoKKw8T9e257nendl3xux27xLU4XB45jeeiBOtpPgDgWQt5C/dql4uHXRxH3pNBmSmMifPTaqZZJbxJxHSXT7cLm5nN2c2q16yQvShEePoqDdP8sjti6mx5J51l7bMpV0Fc62HVuVls004dq95WzbpHTA7BeFnPjsmaQBLDdkDD8tT+siWlr2CaA7wMosy5GYoc/GVuPmNjzYV5LEMJS1LnyXEjZBYsmxsW1rAmneVtqWN1FdXMoJQ9Vhqv1MxK1OlMU1HHdHvqWGUVl7+9k5XzsBVrSpjujDd6HfmzHZcx016zMJ02g2Voq/m9eV1tKWfNUsCA4eVyKmEZ6RpW/paO6d6qZJWtNjZoLOdhXGZaHbN5naz7lxq2Il3kzQ8RXsjrOyCMhGXK4wa1QxG3+lNb5D0D8hceTmuU8JAjg5V/PAFTShztP556U2Iyy24NS88tZ3VvlbPqMJOO127g98oYzWdLrPclGDfr5nUyljfRkKGOtdmVi7jgslvH61S5kvG6mZvfQ5jCxn5PncxgCDMjxkKYamOZoe8UhAdiekPYO8bf69xR+XjPNPN3oI0NfcvP++pY0W4b8/L211Bl8JsoeR6VPOzra7wtbWxmg24366zaxAyXvTxtG2s+6eafDazyqIg9xNq2iPdJxMlgdWYLa9um5DOF3CP+KLphWvD11mPZu2k40amNMi0Xm3tuYq74WVolJASfGfXLmpDW/SHXvkrYdwixoQr3xf+TvCI+lxaSk+Ob2jiON8EoewONwfxV0MazG1ts1OMjvKh1dYvXIx8J8y8x8mhiNBhnuWYOPqory0dn7ic49GJQa7zlgfRhPcrLgDe+rADeNyJyR0woyU9poV05rtRk4q43IWNeE8kxFn0nWv9TztlGLDPl4Ny/ZyoBo1h3zYNuyRdoL461NO9CB5+RFBdHpg0gl28OL7+7A6XVwLttxaML/YH2F/6+iM2KYqIl0o3Izd+vCGL2LVHxwHTQjKUvF4b2VcMSWo66oX05ZyQvz/EqLOorwNX60TBxX3NtPvqL/4AK4S13hZejPQ3tsrysaJxnRs5JIP9UDr4JDvtmO7DrJTj4jDx5Xw1M2ftRIVwznl8NF5erIe33+KdH+QxyQMK9z2uBA6U8bjuKQ7w5pwhZLUwrXLOtG2evQQy8J6tZRqILarOZG5EL6ZHHLJKus5NtGtPJIZ01nBGD3mhyCjtmYaMUez1izQISmiHc4LO8f9nEGow9rMdkYLqqEpY1MkMQs9BNrPyAhQ05ulnduvIRB4ahTytZSVUb65EsrFmbruz34LOY3Dyms7qZU2pj5ev4bEqp76FP61h5Lp/Rratk3WJvzYU2VpQuZnDNzBJYEeazd93OztGRt3i2d4Ku3XxkvqeBlfNZZtE2PiveY+CjduU7jpDRyL4TMdMZca7g7SuLj/DF3qugsAYRJk6tDbwsOv5cPGxbA2sz+e9o25fF6vrkU//7zD8s78R2zkiUGVAIYurUwDTbuie4Cs8VyUY+fRp3akwQ8eLlL5PwKuIveHCH/q2T9ewuYhmbp34K/l1CdPrRNs8JJq8Q/Jsbi44ESV54XQUUguhAgzzd3FwJpIsOVXTmIxsMudJorWYNZpFikLUJE3RACRzWhJis5c2C6wL58T6Gd/YR/ZJQCjt4G3GHKYMRhAde9A23wtttxHNSNn3pWI99kLevci478bC8De6rY21WG7McruOKK9AQeZ7b/GW27dk0mrd4Fq54Oq0W1n20hzkuCxNuFqs+qniiTTHTbjIK4OjYikZsx77i+Pw5HO+XojH5bex7Ib74BBEv4neL9Ic/gHRLTPbnAjfvR3ZpBTY8mza+6WwWI8xC5txvsD3Kr/9GmIyum9H4ZvDPhnjhcNxEWlqKci3IxOaGh2FakA+cDMr3dCPm7VuML9qK4dz/NJ5pvR/F2Wm4V3wnFuPna/HrJ/V46pO1cpwII5XPBemzbljOO2DpNaDjqUOKiUZgReOD9Ujt7oIWHWi5XICy7ChGJVcHXlozCK05ygbWSx0ozRvC9i+2Q60EjSCePWASCpiMKpfDN2eymx4VZsoEK6uFGcHLBo/UMUOsn7EIQiyo1H0aqZcJgrh9TM8Mwb+vJCTfoBmCGOFH2+fh/HgTS9oYZUZ3uZNtSi9hzco+CXl/StieGPHTH1l7bMx2uG1kATiEcWYIYpYysjfEGzpMH50hDLHunZtY1rpKPhuYmG3kdjKDO5VVWFpai+I4FodVT2hRG+v/JxAEcVtITSuENDTVuwOWI7MyFRZ7kAvsrVFH3bTsYqzus2Fw5JeQPTB1mJGc+RMUil/fHfl1Wh7+GzMu9YkZwVqsfdQ/13N+NSR/Wjs6RvY1iP+zsnBfKXYMqyNH+MNWNO12orC+EGnJapRtTUP3ruAfawSGBjpR/OTDvEfj9/wwdA+RcH9eIC/6p2H1rw7hDx/tjtv54E7g+zs5yjlBEERMUrwX8KszKXjl6VH3FvGf3lo/NODjI1ZY/scDz/9ewM0Fq/DA/UqEEYYxMODBY4+Fu8bMweKVOXC/14BT30vBrfMmHPmoD32Gj+H4v3T8uGgdNmScQc2uU7jnBzcx8NtTUOWux9JFjyHvHy5AV2uEJ2UOHL814lb+RmSm/RA3DHrYk1IxfLYLF5COa+Ze3Fi0GqufXOi3uty/GKrB/8IDP3sV6pDn5B28/k/Iei3Iy+hvFuLHT/hg0Nvx2JOL5fT3uCSc/Opvce/A55i7Zh2W/sAfVXgZSR8cQcpPNofle/cwY2sIBEHc7UhoKupF9kcVkSPrcYnP7VR2wxZuo7dUoy7MCj6PD6oIl1vhYooIV1w5r5gupx4Ym83I+XnhpNeMoudvRWPJINb/ZzQX+7uD2/jjdgRB3F2osf5FG4y9oyad+ElF8QuxlYFAJTpYMQSfE6kMBJHKQMDjRgmX81LOA0jvPogH35WAi51wPrI6IQeCaPn7TnXD99L6u1YZCEghEAQRN6nFb+Dh402wRvx3wziYCS+ZMVia/SrW3jChvlcNbTTPokQYtqL1v5/D9twpzneGIZMRQRATxAFpIAVqZeGWAFwDElSPqu96t2VSCARBEIQMmYwIgiAIGVIIBEEQhAwpBIIgCEKGFAJBEAQhQwqBIAiCkCGFQBAEQXCA/wdVP7vju12IIQAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "239_RWfwey9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define learning rate scheduler (Power scheduling)\n",
        "initial_learning_rate = 0.01\n",
        "decay_rate = 0.01\n",
        "power = 0.5\n",
        "def lr_scheduler(epoch):\n",
        "    return initial_learning_rate / (1 + decay_rate * epoch) ** power\n",
        "\n",
        "# Step 4: Compile the model with SGD optimizer and learning rate scheduler\n",
        "optimizer = SGD(learning_rate=initial_learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model with learning rate scheduler\n",
        "scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[scheduler_callback])\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpaI9DaQevkf",
        "outputId": "378f1497-cd2e-4936-b046-89788a5757a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 6s 3ms/step - loss: 0.7241 - accuracy: 0.8164 - val_loss: 0.3780 - val_accuracy: 0.9003 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3627 - accuracy: 0.8995 - val_loss: 0.3119 - val_accuracy: 0.9123 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3107 - accuracy: 0.9117 - val_loss: 0.2769 - val_accuracy: 0.9233 - lr: 0.0099\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2798 - accuracy: 0.9213 - val_loss: 0.2551 - val_accuracy: 0.9291 - lr: 0.0099\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2572 - accuracy: 0.9275 - val_loss: 0.2370 - val_accuracy: 0.9336 - lr: 0.0098\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2386 - accuracy: 0.9332 - val_loss: 0.2252 - val_accuracy: 0.9361 - lr: 0.0098\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2229 - accuracy: 0.9377 - val_loss: 0.2115 - val_accuracy: 0.9419 - lr: 0.0097\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2093 - accuracy: 0.9415 - val_loss: 0.2011 - val_accuracy: 0.9450 - lr: 0.0097\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1977 - accuracy: 0.9440 - val_loss: 0.1918 - val_accuracy: 0.9473 - lr: 0.0096\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1873 - accuracy: 0.9473 - val_loss: 0.1839 - val_accuracy: 0.9495 - lr: 0.0096\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.9483\n",
            "Test Accuracy: 0.9483000040054321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exponential Scheduling"
      ],
      "metadata": {
        "id": "R_KvZcsoe7lU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "D8qy_9nte82B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define learning rate scheduler (Exponential scheduling)\n",
        "initial_learning_rate = 0.01\n",
        "decay_rate = 0.1\n",
        "def lr_scheduler(epoch):\n",
        "    return initial_learning_rate * tf.math.exp(-decay_rate * epoch)\n",
        "\n",
        "# Step 4: Compile the model with SGD optimizer and learning rate scheduler\n",
        "optimizer = SGD(learning_rate=initial_learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model with learning rate scheduler\n",
        "scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[scheduler_callback])\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkSnHfV3fAOJ",
        "outputId": "e3233478-fd46-4acd-dcf1-e40cfcb609b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7259 - accuracy: 0.8209 - val_loss: 0.3837 - val_accuracy: 0.8966 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3691 - accuracy: 0.8968 - val_loss: 0.3154 - val_accuracy: 0.9110 - lr: 0.0090\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3188 - accuracy: 0.9100 - val_loss: 0.2860 - val_accuracy: 0.9193 - lr: 0.0082\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2906 - accuracy: 0.9191 - val_loss: 0.2652 - val_accuracy: 0.9259 - lr: 0.0074\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2708 - accuracy: 0.9240 - val_loss: 0.2513 - val_accuracy: 0.9306 - lr: 0.0067\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2556 - accuracy: 0.9289 - val_loss: 0.2400 - val_accuracy: 0.9342 - lr: 0.0061\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2436 - accuracy: 0.9326 - val_loss: 0.2300 - val_accuracy: 0.9377 - lr: 0.0055\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2337 - accuracy: 0.9352 - val_loss: 0.2230 - val_accuracy: 0.9391 - lr: 0.0050\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2253 - accuracy: 0.9379 - val_loss: 0.2164 - val_accuracy: 0.9423 - lr: 0.0045\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2184 - accuracy: 0.9393 - val_loss: 0.2114 - val_accuracy: 0.9431 - lr: 0.0041\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9425\n",
            "Test Accuracy: 0.9424999952316284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Piecewise Constant Scheduling"
      ],
      "metadata": {
        "id": "fKuKgsTXfExu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Define piecewise constant learning rate schedule\n",
        "boundaries = [5, 10]  # Epochs at which to change learning rate\n",
        "values = [0.01, 0.005, 0.001]  # Learning rates at each boundary\n",
        "learning_rate_fn = PiecewiseConstantDecay(boundaries, values)\n",
        "\n",
        "# Step 4: Compile the model with SGD optimizer and piecewise constant learning rate\n",
        "optimizer = SGD(learning_rate=learning_rate_fn)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=15, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9dPk0YSfGLP",
        "outputId": "8ff261bb-ade0-41c7-b8b4-45afdb6d46de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 1.7467 - accuracy: 0.5296 - val_loss: 1.2750 - val_accuracy: 0.7533\n",
            "Epoch 2/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 1.0520 - accuracy: 0.7810 - val_loss: 0.8333 - val_accuracy: 0.8330\n",
            "Epoch 3/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.7682 - accuracy: 0.8304 - val_loss: 0.6506 - val_accuracy: 0.8567\n",
            "Epoch 4/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6360 - accuracy: 0.8501 - val_loss: 0.5563 - val_accuracy: 0.8690\n",
            "Epoch 5/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5604 - accuracy: 0.8624 - val_loss: 0.4985 - val_accuracy: 0.8802\n",
            "Epoch 6/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5113 - accuracy: 0.8716 - val_loss: 0.4599 - val_accuracy: 0.8864\n",
            "Epoch 7/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4768 - accuracy: 0.8775 - val_loss: 0.4321 - val_accuracy: 0.8905\n",
            "Epoch 8/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4509 - accuracy: 0.8820 - val_loss: 0.4109 - val_accuracy: 0.8939\n",
            "Epoch 9/15\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.4306 - accuracy: 0.8856 - val_loss: 0.3946 - val_accuracy: 0.8956\n",
            "Epoch 10/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4143 - accuracy: 0.8894 - val_loss: 0.3809 - val_accuracy: 0.8970\n",
            "Epoch 11/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4007 - accuracy: 0.8921 - val_loss: 0.3696 - val_accuracy: 0.8999\n",
            "Epoch 12/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3892 - accuracy: 0.8943 - val_loss: 0.3601 - val_accuracy: 0.9019\n",
            "Epoch 13/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3791 - accuracy: 0.8961 - val_loss: 0.3517 - val_accuracy: 0.9031\n",
            "Epoch 14/15\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3703 - accuracy: 0.8991 - val_loss: 0.3444 - val_accuracy: 0.9052\n",
            "Epoch 15/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3626 - accuracy: 0.9006 - val_loss: 0.3379 - val_accuracy: 0.9069\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.9082\n",
            "Test Accuracy: 0.9082000255584717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performance Scheduling"
      ],
      "metadata": {
        "id": "i5YAoua1fNhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model with SGD optimizer\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Define performance-based learning rate scheduler\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=0.0001)\n",
        "\n",
        "# Step 5: Train the model with performance-based learning rate scheduler\n",
        "history = model.fit(x_train, y_train, epochs=15, batch_size=32, validation_split=0.2, callbacks=[reduce_lr_callback])\n",
        "\n",
        "# Step 6: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljCOsX2PfNTJ",
        "outputId": "c846d097-3a33-4a8f-dc7c-a12c4b233fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7193 - accuracy: 0.8195 - val_loss: 0.3775 - val_accuracy: 0.9009 - lr: 0.0100\n",
            "Epoch 2/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3590 - accuracy: 0.9005 - val_loss: 0.3064 - val_accuracy: 0.9158 - lr: 0.0100\n",
            "Epoch 3/15\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3068 - accuracy: 0.9134 - val_loss: 0.2743 - val_accuracy: 0.9230 - lr: 0.0100\n",
            "Epoch 4/15\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2765 - accuracy: 0.9214 - val_loss: 0.2526 - val_accuracy: 0.9293 - lr: 0.0100\n",
            "Epoch 5/15\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2542 - accuracy: 0.9285 - val_loss: 0.2361 - val_accuracy: 0.9340 - lr: 0.0100\n",
            "Epoch 6/15\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2360 - accuracy: 0.9333 - val_loss: 0.2230 - val_accuracy: 0.9367 - lr: 0.0100\n",
            "Epoch 7/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2206 - accuracy: 0.9377 - val_loss: 0.2104 - val_accuracy: 0.9426 - lr: 0.0100\n",
            "Epoch 8/15\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2075 - accuracy: 0.9422 - val_loss: 0.1997 - val_accuracy: 0.9450 - lr: 0.0100\n",
            "Epoch 9/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1959 - accuracy: 0.9448 - val_loss: 0.1901 - val_accuracy: 0.9480 - lr: 0.0100\n",
            "Epoch 10/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1854 - accuracy: 0.9478 - val_loss: 0.1831 - val_accuracy: 0.9509 - lr: 0.0100\n",
            "Epoch 11/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1759 - accuracy: 0.9505 - val_loss: 0.1749 - val_accuracy: 0.9530 - lr: 0.0100\n",
            "Epoch 12/15\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1673 - accuracy: 0.9525 - val_loss: 0.1697 - val_accuracy: 0.9541 - lr: 0.0100\n",
            "Epoch 13/15\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1595 - accuracy: 0.9550 - val_loss: 0.1619 - val_accuracy: 0.9562 - lr: 0.0100\n",
            "Epoch 14/15\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1523 - accuracy: 0.9569 - val_loss: 0.1567 - val_accuracy: 0.9573 - lr: 0.0100\n",
            "Epoch 15/15\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1457 - accuracy: 0.9590 - val_loss: 0.1515 - val_accuracy: 0.9582 - lr: 0.0100\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.9564\n",
            "Test Accuracy: 0.9563999772071838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avoiding Overfitting Through Regularization\n"
      ],
      "metadata": {
        "id": "QsgqzDFof2lH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 and 2 Regularization"
      ],
      "metadata": {
        "id": "8lQKJ74Kf3-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model with 1 and 2 regularization\n",
        "model = Sequential([\n",
        "    InputLayer(input_shape=(784,)),\n",
        "    Dense(100, activation='elu', kernel_initializer='he_normal',\n",
        "          kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2ph191nf6rv",
        "outputId": "949542cd-67e0-4734-a793-74672cd63b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6874 - accuracy: 0.8789 - val_loss: 0.4859 - val_accuracy: 0.9021\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4753 - accuracy: 0.8977 - val_loss: 0.4231 - val_accuracy: 0.9164\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4405 - accuracy: 0.9088 - val_loss: 0.3927 - val_accuracy: 0.9243\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4248 - accuracy: 0.9141 - val_loss: 0.4160 - val_accuracy: 0.9145\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4070 - accuracy: 0.9193 - val_loss: 0.3829 - val_accuracy: 0.9246\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3962 - accuracy: 0.9228 - val_loss: 0.3694 - val_accuracy: 0.9339\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3856 - accuracy: 0.9266 - val_loss: 0.3668 - val_accuracy: 0.9320\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3758 - accuracy: 0.9271 - val_loss: 0.3439 - val_accuracy: 0.9381\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3699 - accuracy: 0.9296 - val_loss: 0.3524 - val_accuracy: 0.9338\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3606 - accuracy: 0.9323 - val_loss: 0.3293 - val_accuracy: 0.9439\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.9406\n",
            "Test Accuracy: 0.9405999779701233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dropout"
      ],
      "metadata": {
        "id": "j1U-AABWgPb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model with Dropout regularization\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),  # Apply Dropout with dropout rate of 0.2 (20%)\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),  # Apply Dropout with dropout rate of 0.2 (20%)\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgc-2CmYgPVm",
        "outputId": "05b63051-6ff3-463b-9248-c2ea3e3cd59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3716 - accuracy: 0.8881 - val_loss: 0.1630 - val_accuracy: 0.9503\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1744 - accuracy: 0.9470 - val_loss: 0.1160 - val_accuracy: 0.9636\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1341 - accuracy: 0.9599 - val_loss: 0.1090 - val_accuracy: 0.9673\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1147 - accuracy: 0.9647 - val_loss: 0.0938 - val_accuracy: 0.9733\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0967 - accuracy: 0.9703 - val_loss: 0.0840 - val_accuracy: 0.9742\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0876 - accuracy: 0.9724 - val_loss: 0.0931 - val_accuracy: 0.9736\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0771 - accuracy: 0.9755 - val_loss: 0.0883 - val_accuracy: 0.9747\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0701 - accuracy: 0.9770 - val_loss: 0.0891 - val_accuracy: 0.9768\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0662 - accuracy: 0.9793 - val_loss: 0.0870 - val_accuracy: 0.9758\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0649 - accuracy: 0.9792 - val_loss: 0.0801 - val_accuracy: 0.9788\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9803\n",
            "Test Accuracy: 0.9803000092506409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monte-Carlo (MC) Dropout\n"
      ],
      "metadata": {
        "id": "glFR4vVPgqKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Step 2: Build the neural network model with Dropout (MC Dropout)\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dropout(0.2),  # Apply Dropout with dropout rate of 0.2 (20%)\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),  # Apply Dropout with dropout rate of 0.2 (20%)\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 5: Perform Monte Carlo (MC) Dropout for uncertainty estimation\n",
        "n_samples = 100  # Number of Monte Carlo samples\n",
        "X_test_scaled = x_test  # Assuming x_test is already scaled if needed\n",
        "\n",
        "# Function to perform MC Dropout and compute probabilistic predictions\n",
        "def predict_with_uncertainty(model, X_test_scaled, n_samples):\n",
        "    y_probas = []\n",
        "    # Set learning phase to 1 (dropout on) using Keras backend\n",
        "    K.set_learning_phase(1)\n",
        "    for _ in range(n_samples):\n",
        "        y_proba = model.predict(X_test_scaled)\n",
        "        y_probas.append(y_proba)\n",
        "    K.set_learning_phase(0)  # Reset learning phase to default (0)\n",
        "\n",
        "    y_probas = np.stack(y_probas, axis=0)  # Stack predictions along new axis\n",
        "    y_mean = np.mean(y_probas, axis=0)  # Compute mean prediction\n",
        "    return y_mean\n",
        "\n",
        "# Step 6: Obtain probabilistic predictions using MC Dropout\n",
        "y_proba = predict_with_uncertainty(model, X_test_scaled, n_samples)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Optional: Compute other uncertainty metrics using y_proba (e.g., variance)\n",
        "y_variance = np.var(y_proba, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkGuvAfMgql2",
        "outputId": "109cb2b7-134d-4d7e-e5d0-7a8cfc1bde51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3700 - accuracy: 0.8872 - val_loss: 0.1521 - val_accuracy: 0.9542\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1772 - accuracy: 0.9470 - val_loss: 0.1172 - val_accuracy: 0.9650\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1353 - accuracy: 0.9591 - val_loss: 0.0993 - val_accuracy: 0.9689\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1145 - accuracy: 0.9646 - val_loss: 0.0926 - val_accuracy: 0.9728\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0988 - accuracy: 0.9692 - val_loss: 0.0871 - val_accuracy: 0.9749\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0885 - accuracy: 0.9726 - val_loss: 0.0947 - val_accuracy: 0.9725\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0801 - accuracy: 0.9750 - val_loss: 0.0929 - val_accuracy: 0.9737\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0746 - accuracy: 0.9763 - val_loss: 0.0858 - val_accuracy: 0.9762\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0679 - accuracy: 0.9780 - val_loss: 0.0877 - val_accuracy: 0.9765\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0665 - accuracy: 0.9783 - val_loss: 0.0859 - val_accuracy: 0.9768\n",
            "  1/313 [..............................] - ETA: 19s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9795\n",
            "Test Accuracy: 0.9794999957084656\n"
          ]
        }
      ]
    }
  ]
}