# -*- coding: utf-8 -*-
"""CB001 - Chapter 11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aGgV0W9SyOWyyouPhp76lNR3zX0i9B8z

# Algorithms for Linear Regression

# Normal Equation doesn't have an imp. in Scikit-Learn because of the direct use of the coefficients in the equation

# Singular Value Descomposition (SVD)
"""

#Mount the google drive connection to our dataset
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""Load the dataset"""

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/AI/datasets/smartphones_sales.csv')

df.head()

df

df.info()

df.drop("Models", axis=1, inplace=True)

df.drop("Colors", axis=1, inplace=True)

df.drop("Mobile", axis=1, inplace=True)

df.drop("Memory", axis=1, inplace=True)

df.drop("Storage", axis=1, inplace=True)

df.info()

df.head()

df.describe()

"""Visualize the data"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

for column in df.columns:
    plt.figure(figsize=(10, 6))

    if df[column].dtype == 'object':
        sns.countplot(x=column, data=df)
        plt.title(f'{column} Count Plot')
        plt.xlabel(column)
        plt.ylabel('Count')
        plt.xticks(rotation=45)

    else:
        sns.histplot(df[column], bins=10, kde=True)
        plt.title(f'Histogram of {column}')
        plt.xlabel(column)
        plt.ylabel('Frequency')

    plt.show()

df.isnull().sum()

df.isna().sum()

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

X = df.drop(columns=['Selling Price'])

numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_features = ['Camera']
ordinal_features=['Brands']

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent'))
])

cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

ordinal_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OrdinalEncoder())
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', cat_transformer, cat_features),
        ('ordinal', ordinal_transformer, ordinal_features)
    ])

"""# SVD Regressor"""

from sklearn.linear_model import LinearRegression
from sklearn.decomposition import TruncatedSVD
from sklearn.pipeline import make_pipeline

svd_lr_model = make_pipeline(TruncatedSVD(n_components=5), LinearRegression())

svd_reg_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', svd_lr_model)
])

y = df['Selling Price']

from sklearn.model_selection import train_test_split

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

svd_reg_pipeline.fit(X_train, y_train)

"""Loss Function => RMSE"""

from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error
import numpy as np

y_train_pred = svd_reg_pipeline.predict(X_train)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))

y_val_pred = svd_reg_pipeline.predict(X_val)
val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))

y_test_pred = svd_reg_pipeline.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

cv_rmse_scores = np.sqrt(-cross_val_score(svd_reg_pipeline, X, y, cv=5, scoring='neg_mean_squared_error'))
cv_rmse_mean = cv_rmse_scores.mean()

print("RMSE for training set:", train_rmse)
print("RMSE for validation set:", val_rmse)
print("RMSE for test set:", test_rmse)
print("Cross-validation RMSE:", cv_rmse_mean)

"""# Batch GD (Not supported in Scikit-Learn)

# Mini-batch GD (Not supported in Scikit-Learn)

# Stochastic GD Regressor
"""

from sklearn.linear_model import SGDRegressor

sgd_regressor = SGDRegressor(loss='squared_error', eta0=0.01, max_iter=1000, tol=1e-3, penalty=None)

sgd_reg_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', sgd_regressor)
])

sgd_reg_pipeline.fit(X_train, y_train)

"""Loss Function => RMSE"""

y_train_pred = sgd_reg_pipeline.predict(X_train)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))

y_val_pred = sgd_reg_pipeline.predict(X_val)
val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))

y_test_pred = sgd_reg_pipeline.predict(X_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

cv_rmse_scores = np.sqrt(-cross_val_score(sgd_reg_pipeline, X, y, cv=5, scoring='neg_mean_squared_error'))
cv_rmse_mean = cv_rmse_scores.mean()

print("RMSE for training set:", train_rmse)
print("RMSE for validation set:", val_rmse)
print("RMSE for test set:", test_rmse)
print("Cross-validation RMSE:", cv_rmse_mean)