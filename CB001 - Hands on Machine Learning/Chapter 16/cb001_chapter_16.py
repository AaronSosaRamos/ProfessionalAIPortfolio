# -*- coding: utf-8 -*-
"""CB001 - Chapter 16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dS68p0DXhzN5bdBqomjTUIRR2QiN5Kn3

#Voting Classifiers
"""

#Mount the google drive connection to our dataset
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/AI/datasets/apple_quality.csv')

df.head()

df.info()

df.drop(df.tail(1).index, inplace=True)
df.drop("A_id", axis=1, inplace=True)
df["Acidity"] = df["Acidity"].astype(float)

df.shape

df.isnull().sum()

df.isna().sum()

import matplotlib.pyplot as plt
import seaborn as sns

def plot_charts(df):
  # Numeric features
  numeric_features = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]
  for feature in numeric_features:
      plt.figure(figsize=(8, 6))
      sns.histplot(df[feature], kde=True, color='blue')
      plt.title(f'Distribution of {feature}')
      plt.xlabel(feature)
      plt.ylabel('Frequency')
      plt.show()

  # Categorical features
  categorical_features = [col for col in df.columns if df[col].dtype == 'object']
  for feature in categorical_features:
      plt.figure(figsize=(8, 6))
      sns.countplot(y=df[feature], order=df[feature].value_counts().index, palette='Set2')
      plt.title(f'Count of {feature}')
      plt.xlabel('Count')
      plt.ylabel(feature)
      plt.show()

plot_charts(df)

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('scaler', StandardScaler())
])

cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

X = df.drop(columns=['Quality'])
y = df['Quality']

X_encoded = numeric_transformer.fit_transform(X)
X_encoded = pd.DataFrame(X_encoded, columns=X.columns)

X_encoded

y_encoded = cat_transformer.fit_transform(y.values.reshape(-1, 1))
y_encoded_df = pd.DataFrame(y_encoded.toarray(), columns=cat_transformer.named_steps['encoder'].get_feature_names_out())
y_encoded_df.drop("x0_bad", axis=1, inplace=True)
print(y_encoded_df.head())

X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y_encoded_df, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

log_clf = LogisticRegression()
rnd_clf = RandomForestClassifier()
svm_clf = SVC()

voting_clf = VotingClassifier(
 estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],
 voting='hard')

voting_clf.fit(X_train, y_train)

accuracy = voting_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = voting_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

from sklearn.metrics import accuracy_score
for clf in (log_clf, rnd_clf, svm_clf, voting_clf):
  clf.fit(X_train, y_train)
  y_pred = clf.predict(X_test)
  print(clf.__class__.__name__, accuracy_score(y_test, y_pred))

from sklearn.metrics import classification_report, confusion_matrix

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=RuntimeWarning)

from yellowbrick.classifier import ROCAUC,ConfusionMatrix
from sklearn.metrics import accuracy_score

def Performance(model):
    global X_train,y_train,X_val,y_val,X_test,X_train

    print("REPORT:")
    print(classification_report(y_val,model.predict(X_val)))
    print(classification_report(y_test,model.predict(X_test)))

from sklearn.model_selection import cross_val_score
def CrossValidationScore(model_list):
    global X_train,y_train

    mean_cross_val_score = []
    model_name           = []

    for model in model_list:
        model_name.append(type(model).__name__)

    for i in model_list:
        scores = cross_val_score(i, X_train, y_train, cv=5)
        mean_cross_val_score.append(scores.mean())

    cvs = pd.DataFrame({"Model Name":model_name,"CVS":mean_cross_val_score})
    return cvs.style.background_gradient("Greens")

Performance(voting_clf)

"""#Bagging"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
bag_clf = BaggingClassifier(
 DecisionTreeClassifier(), n_estimators=500,
 max_samples=100, bootstrap=True, n_jobs=-1)
bag_clf.fit(X_train, y_train)

accuracy = bag_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = bag_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(bag_clf)

"""#Pasting"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
pas_clf = BaggingClassifier(
 DecisionTreeClassifier(), n_estimators=500,
 max_samples=100, bootstrap=False, n_jobs=-1)
pas_clf.fit(X_train, y_train)

accuracy = pas_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = pas_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(pas_clf)

"""#Out-of-Bag Explanation"""

bag_clf.oob_score

pas_clf.oob_score

"""#Random Patches"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
bag_rp_clf = BaggingClassifier(
 DecisionTreeClassifier(), n_estimators=500,
 max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=True, n_jobs=-1)
bag_rp_clf.fit(X_train, y_train)

accuracy = bag_rp_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = bag_rp_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(bag_rp_clf)

"""#Random Subspaces"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
bag_rs_clf = BaggingClassifier(
 DecisionTreeClassifier(), n_estimators=500,
 max_samples=1.0, bootstrap=False, bootstrap_features=True,  max_features=0.99, n_jobs=-1)
bag_rs_clf.fit(X_train, y_train)

accuracy = bag_rs_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = bag_rs_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(bag_rs_clf)

"""#Random Forests

"""

from sklearn.ensemble import RandomForestClassifier
rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)
rnd_clf.fit(X_train, y_train)

accuracy = rnd_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = rnd_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(rnd_clf)

"""#Feature Importance"""

for name, score in zip(df[df.columns], rnd_clf.feature_importances_):
  print(name, score)

"""Simulation of Random Forest Classifier with Bagging Classifier"""

sim_bag_clf = BaggingClassifier(
 DecisionTreeClassifier(splitter="random", max_leaf_nodes=16),
 n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)

sim_bag_clf.fit(X_train, y_train)

accuracy = sim_bag_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = sim_bag_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(sim_bag_clf)

"""#Extra-Trees"""

from sklearn.ensemble import ExtraTreesClassifier
et_clf = ExtraTreesClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)
et_clf.fit(X_train, y_train)

accuracy = et_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = et_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(et_clf)

"""#Ada Boosting"""

from sklearn.ensemble import AdaBoostClassifier
ada_clf = AdaBoostClassifier(
 DecisionTreeClassifier(max_depth=1), n_estimators=200,
 algorithm="SAMME.R", learning_rate=0.5)
ada_clf.fit(X_train, y_train)

accuracy = ada_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = ada_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(ada_clf)

"""#Gradient Boosting"""

from sklearn.ensemble import GradientBoostingRegressor
gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)
gbrt.fit(X_train, y_train)

accuracy = gbrt.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = gbrt.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

"""With the optimal number of trees"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor

gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)
gbrt.fit(X_train, y_train)
errors = [mean_squared_error(y_val, y_pred)
 for y_pred in gbrt.staged_predict(X_val)]
bst_n_estimators = np.argmin(errors)
gbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators)
gbrt_best.fit(X_train, y_train)

accuracy = gbrt_best.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = gbrt_best.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

"""Early stopping"""

gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)
min_val_error = float("inf")
error_going_up = 0
for n_estimators in range(1, 120):
  gbrt.n_estimators = n_estimators
  gbrt.fit(X_train, y_train)
  y_pred = gbrt.predict(X_val)
  val_error = mean_squared_error(y_val, y_pred)
  if val_error < min_val_error:
    min_val_error = val_error
    error_going_up = 0
  else:
    error_going_up += 1
    if error_going_up == 5:
      break # early stopping

"""#XGBoost"""

import xgboost
xgb_clf = xgboost.XGBClassifier()
xgb_clf.fit(X_train, y_train,
 eval_set=[(X_val, y_val)], early_stopping_rounds=2)

accuracy = xgb_clf.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = xgb_clf.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

Performance(xgb_clf)