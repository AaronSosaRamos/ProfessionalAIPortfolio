# -*- coding: utf-8 -*-
"""CB001 - Chapter 15.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zN5USnLgDE1OwAhst27uMJG14sEgSe3t

#Decision Trees

#Classification Tasks
"""

#Mount the google drive connection to our dataset
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/AI/datasets/apple_quality.csv')

df.head()

df.info()

df.drop(df.tail(1).index, inplace=True)

df.drop("A_id", axis=1, inplace=True)

df["Acidity"] = df["Acidity"].astype(float)

df.shape

df.isnull().sum()

df.isna().sum()

import matplotlib.pyplot as plt
import seaborn as sns

def plot_charts(df):
  # Numeric features
  numeric_features = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]
  for feature in numeric_features:
      plt.figure(figsize=(8, 6))
      sns.histplot(df[feature], kde=True, color='blue')
      plt.title(f'Distribution of {feature}')
      plt.xlabel(feature)
      plt.ylabel('Frequency')
      plt.show()

  # Categorical features
  categorical_features = [col for col in df.columns if df[col].dtype == 'object']
  for feature in categorical_features:
      plt.figure(figsize=(8, 6))
      sns.countplot(y=df[feature], order=df[feature].value_counts().index, palette='Set2')
      plt.title(f'Count of {feature}')
      plt.xlabel('Count')
      plt.ylabel(feature)
      plt.show()

plot_charts(df)

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('scaler', StandardScaler())
])

cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier()

X = df.drop(columns=['Quality'])
y = df['Quality']

X_encoded = numeric_transformer.fit_transform(X)
X_encoded = pd.DataFrame(X_encoded, columns=X.columns)

X_encoded

y_encoded = cat_transformer.fit_transform(y.values.reshape(-1, 1))
y_encoded_df = pd.DataFrame(y_encoded.toarray(), columns=cat_transformer.named_steps['encoder'].get_feature_names_out())
y_encoded_df.drop("x0_bad", axis=1, inplace=True)
print(y_encoded_df.head())

X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y_encoded_df, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 5, 10, 20, 30],
    'min_samples_split': [2, 5, 10, 15],
    'min_samples_leaf': [1, 2, 4, 8],
    'max_features': ['auto', 'sqrt', 'log2', None],
}


grid_search = GridSearchCV(dtc, param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

best_model = grid_search.best_estimator_
print("Best parameters found:", grid_search.best_params_)

accuracy = best_model.score(X_val, y_val)
print("Accuracy of the best model in validation dataset:", accuracy)

accuracy = best_model.score(X_test, y_test)
print("Accuracy of the best model in test dataset:", accuracy)

from sklearn.metrics import classification_report, confusion_matrix

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=RuntimeWarning)

from yellowbrick.classifier import ROCAUC,ConfusionMatrix
from sklearn.metrics import accuracy_score

def Performance(model):
    global X_train,y_train,X_val,y_val,X_test,X_train

    print("REPORT:")
    print(classification_report(y_val,model.predict(X_val)))
    print(classification_report(y_test,model.predict(X_test)))

    visualizer = ROCAUC(model)
    visualizer.fit(X_train, y_train)
    visualizer.score(X_val, y_val)
    visualizer.score(X_test, y_test)
    visualizer.show();

    plt.figure(figsize=(3,3))
    cm = ConfusionMatrix(model)
    cm.fit(X_train, y_train)
    cm.score(X_val, y_val)
    cm.score(X_test, y_test)
    plt.xticks(rotation=0)
    cm.show();

from sklearn.model_selection import cross_val_score
def CrossValidationScore(model_list):
    global X_train,y_train

    mean_cross_val_score = []
    model_name           = []

    for model in model_list:
        model_name.append(type(model).__name__)

    for i in model_list:
        scores = cross_val_score(i, X_train, y_train, cv=5)
        mean_cross_val_score.append(scores.mean())

    cvs = pd.DataFrame({"Model Name":model_name,"CVS":mean_cross_val_score})
    return cvs.style.background_gradient("Greens")

Performance(best_model)

CrossValidationScore([best_model])

"""#Regression Tasks"""

import pandas as pd
df_regression = pd.read_csv('/content/drive/My Drive/AI/datasets/housing.csv')

df_regression.head()

df_regression.drop("Unnamed: 0",axis=1,inplace=True)

df_regression.info()

df_regression.shape

df_regression.describe()

plot_charts(df_regression)

df_regression.isnull().sum()

df_regression.isna().sum()

X = df_regression.drop("MedHouseVal", axis=1)
y = df_regression["MedHouseVal"]

X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

X_encoded = numeric_transformer.fit_transform(X)
X_encoded = pd.DataFrame(X_encoded, columns=X.columns)

from sklearn.tree import DecisionTreeRegressor

dtr = DecisionTreeRegressor(criterion='squared_error', max_depth=10, min_samples_split=4, min_samples_leaf=4, max_features=None)

from sklearn.metrics import mean_squared_error
import numpy as np

dtr.fit(X_train, y_train)

y_val_pred = dtr.predict(X_val)

score = np.sqrt(mean_squared_error(y_val, y_val_pred))
print("RMSE of the model in validation dataset:", score)

y_test_pred = dtr.predict(X_test)

score = np.sqrt(mean_squared_error(y_test, y_test_pred))
print("RMSE of the model in test dataset:", score)

from sklearn.model_selection import cross_val_score
def CrossValidationScore(model_list):
    global X_train,y_train

    mean_cross_val_score = []
    model_name           = []

    for model in model_list:
        model_name.append(type(model).__name__)

    for i in model_list:
        scores = cross_val_score(i, X_train, y_train, cv=5)
        mean_cross_val_score.append(scores.mean())

    cvs = pd.DataFrame({"Model Name":model_name,"CVS":mean_cross_val_score})
    return cvs.style.background_gradient("Greens")

CrossValidationScore([dtr])