{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1809bbf275648ec8fbababf7b5239e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aaee591cf686474da6e1145d1450b698",
              "IPY_MODEL_ece6490e8f494f5bb91a82ab01529d09",
              "IPY_MODEL_49db65a6e1fd427b8fc761c80d0e8262"
            ],
            "layout": "IPY_MODEL_e65f26adc77e4206bd8677a29e83ebb4"
          }
        },
        "aaee591cf686474da6e1145d1450b698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f00e8fd446744f2b10e8cd41f48d0bc",
            "placeholder": "​",
            "style": "IPY_MODEL_395b13563fc242b7ad197bb0f5a0e78c",
            "value": "Dl Completed...: 100%"
          }
        },
        "ece6490e8f494f5bb91a82ab01529d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f17f4cb011a4b55a1b95355a60f6f1a",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1b055ea4d82433898663b79baba66cf",
            "value": 5
          }
        },
        "49db65a6e1fd427b8fc761c80d0e8262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd90dd207104424ad6340ad6814ccb6",
            "placeholder": "​",
            "style": "IPY_MODEL_e0aa43d828e84c88a3b69680f1fbe66e",
            "value": " 5/5 [00:00&lt;00:00,  9.77 file/s]"
          }
        },
        "e65f26adc77e4206bd8677a29e83ebb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f00e8fd446744f2b10e8cd41f48d0bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "395b13563fc242b7ad197bb0f5a0e78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f17f4cb011a4b55a1b95355a60f6f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b055ea4d82433898663b79baba66cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fd90dd207104424ad6340ad6814ccb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0aa43d828e84c88a3b69680f1fbe66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1.  Categorical Features"
      ],
      "metadata": {
        "id": "uuKWRqW7LiEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`categorical_column_with_identity`"
      ],
      "metadata": {
        "id": "cbsR2h6gLvQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This column is useful when the values of the feature are integers in a contiguous range.\n",
        "\n"
      ],
      "metadata": {
        "id": "bTaQaXY_LkGn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNO1jcczK5Nx",
        "outputId": "8ef63529-250e-4c08-ba9f-c53965142532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-78f308103763>:4: categorical_column_with_identity (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-1-78f308103763>:11: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]], shape=(5, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the feature column\n",
        "identity_column = tf.feature_column.categorical_column_with_identity(\n",
        "    key='identity_column', num_buckets=5)\n",
        "\n",
        "# Example input\n",
        "features = {'identity_column': [0, 1, 2, 3, 4]}\n",
        "\n",
        "# Create a dense tensor from the feature column\n",
        "identity_column_indicator = tf.feature_column.indicator_column(identity_column)\n",
        "tensor = tf.keras.layers.DenseFeatures([identity_column_indicator])(features)\n",
        "\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`categorical_column_with_vocabulary_list`"
      ],
      "metadata": {
        "id": "gF0N6M_DLxVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This column is useful when you know all possible values of the feature and can list them.\n",
        "\n"
      ],
      "metadata": {
        "id": "PNjS9qpDL2Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the feature column\n",
        "vocabulary_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    key='vocabulary_column', vocabulary_list=['apple', 'banana', 'cherry'])\n",
        "\n",
        "# Example input\n",
        "features = {'vocabulary_column': ['apple', 'banana', 'apple', 'cherry', 'banana']}\n",
        "\n",
        "# Create a dense tensor from the feature column\n",
        "vocabulary_column_indicator = tf.feature_column.indicator_column(vocabulary_column)\n",
        "tensor = tf.keras.layers.DenseFeatures([vocabulary_column_indicator])(features)\n",
        "\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B5CMAWjL08u",
        "outputId": "8b14f880-fff8-4a2d-da46-3c11d791e239"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-41d12e49a9e1>:4: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]], shape=(5, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`categorical_column_with_vocabulary_file`"
      ],
      "metadata": {
        "id": "zYfEXPwbL92H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This column is useful when you have a large vocabulary stored in a file.\n"
      ],
      "metadata": {
        "id": "aa4fdcd6MCph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a vocabulary file\n",
        "vocabulary_file = 'vocabulary.txt'\n",
        "with open(vocabulary_file, 'w') as f:\n",
        "    f.write('\\n'.join(['apple', 'banana', 'cherry']))\n",
        "\n",
        "# Define the feature column\n",
        "vocabulary_file_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
        "    key='vocabulary_file_column', vocabulary_file=vocabulary_file, num_oov_buckets=1)\n",
        "\n",
        "# Example input\n",
        "features = {'vocabulary_file_column': ['apple', 'banana', 'apple', 'cherry', 'banana']}\n",
        "\n",
        "# Create a dense tensor from the feature column\n",
        "vocabulary_file_column_indicator = tf.feature_column.indicator_column(vocabulary_file_column)\n",
        "tensor = tf.keras.layers.DenseFeatures([vocabulary_file_column_indicator])(features)\n",
        "\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf3eAJ0cMCWN",
        "outputId": "a8d4c3b0-b05f-40f3-e5c0-172908e76a2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-e18d08e19771>:9: categorical_column_with_vocabulary_file_v2 (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]], shape=(5, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`categorical_column_with_hash_bucket`"
      ],
      "metadata": {
        "id": "g2atI8YKMHRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This column is useful when the possible values of the feature are not known or are very large.\n",
        "\n"
      ],
      "metadata": {
        "id": "vmBoCGGeMLdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the feature column\n",
        "hash_bucket_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "    key='hash_bucket_column', hash_bucket_size=10)\n",
        "\n",
        "# Example input\n",
        "features = {'hash_bucket_column': ['apple', 'banana', 'cherry', 'date', 'elderberry']}\n",
        "\n",
        "# Create a dense tensor from the feature column\n",
        "hash_bucket_column_indicator = tf.feature_column.indicator_column(hash_bucket_column)\n",
        "tensor = tf.keras.layers.DenseFeatures([hash_bucket_column_indicator])(features)\n",
        "\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILpShexEMNNf",
        "outputId": "48767e16-f1d7-4c97-fe72-ad6b0db1b2f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-e1e36b23b1a4>:4: categorical_column_with_hash_bucket (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]], shape=(5, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.  Crossed Categorical Features\n"
      ],
      "metadata": {
        "id": "uGZZXaTiMwBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`tf.feature_column.bucketized_column`"
      ],
      "metadata": {
        "id": "YXSpYcO4Mw3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This column type is used to transform continuous features into categorical features by placing them into specified buckets.\n",
        "\n"
      ],
      "metadata": {
        "id": "o1AWU40iNARR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the feature column\n",
        "age = tf.feature_column.numeric_column('age')\n",
        "\n",
        "# Define the bucket boundaries\n",
        "age_buckets = tf.feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "\n",
        "# Example input\n",
        "features = {'age': [15, 20, 28, 35, 42, 50, 58, 65, 70]}\n",
        "\n",
        "# Create a dense tensor from the feature column\n",
        "bucketized_column_indicator = tf.feature_column.indicator_column(age_buckets)\n",
        "tensor = tf.keras.layers.DenseFeatures([bucketized_column_indicator])(features)\n",
        "\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w63myORXNAsZ",
        "outputId": "6d050438-8916-4da3-d0f0-41674196fcbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-3b935b98e437>:4: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-5-3b935b98e437>:7: bucketized_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]], shape=(9, 11), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`tf.feature_column.crossed_column`"
      ],
      "metadata": {
        "id": "sm1O2m59NGok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This column type is used to create a single categorical feature by crossing two or more categorical features.\n",
        "\n"
      ],
      "metadata": {
        "id": "2hLKTmHXNIUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define individual categorical columns\n",
        "age_buckets = tf.feature_column.bucketized_column(\n",
        "    tf.feature_column.numeric_column('age'), boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "\n",
        "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    key='education', vocabulary_list=['HighSchool', 'Bachelors', 'Masters', 'PhD'])\n",
        "\n",
        "# Cross the age and education columns\n",
        "age_education_crossed = tf.feature_column.crossed_column(\n",
        "    [age_buckets, education], hash_bucket_size=1000)\n",
        "\n",
        "# Example input\n",
        "features = {\n",
        "    'age': [25, 30, 45, 50, 65],\n",
        "    'education': ['Bachelors', 'PhD', 'Masters', 'HighSchool', 'Bachelors']\n",
        "}\n",
        "\n",
        "# Create a dense tensor from the crossed column\n",
        "age_education_crossed_indicator = tf.feature_column.indicator_column(age_education_crossed)\n",
        "tensor = tf.keras.layers.DenseFeatures([age_education_crossed_indicator])(features)\n",
        "\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i95Qsu8kNJWe",
        "outputId": "35747a9f-7ed0-42f8-e7d6-98cc570399f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-ad9fc0d3c4c9>:11: crossed_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.experimental.preprocessing.HashedCrossing` instead for feature crossing when preprocessing data to train a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(5, 1000), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Encoding Categorical Features Using One-Hot Vectors\n"
      ],
      "metadata": {
        "id": "KiF_Ey0jNdyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  One-Hot vectors => Few categories\n",
        "*  Embeddings => Large vocabulary\n",
        "\n"
      ],
      "metadata": {
        "id": "eDnhZFV7Nf3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`indicator_column`"
      ],
      "metadata": {
        "id": "hPQDoXUyNtxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An indicator_column in TensorFlow is used to convert categorical columns into dense one-hot encoded vectors."
      ],
      "metadata": {
        "id": "bntyHx6FNzCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the categorical column\n",
        "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    key='education', vocabulary_list=['HighSchool', 'Bachelors', 'Masters', 'PhD'])\n",
        "\n",
        "# Convert the categorical column to an indicator column\n",
        "education_indicator = tf.feature_column.indicator_column(education)\n",
        "\n",
        "# Example input\n",
        "features = {'education': ['Bachelors', 'PhD', 'Masters', 'HighSchool', 'Bachelors']}\n",
        "\n",
        "# Create a dense tensor from the indicator column\n",
        "tensor = tf.keras.layers.DenseFeatures([education_indicator])(features)\n",
        "\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vOE_SgwNkV9",
        "outputId": "b79f53a8-1486-4aa8-bd40-83c9333f65fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]], shape=(5, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Less than 10 => One-Hot Enconding\n",
        "*   More than 50 => Embeddings\n",
        "*   Between 10 and 50 => Test both of them\n",
        "\n"
      ],
      "metadata": {
        "id": "MsHdcHFPOEsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An embedding is a trainable dense vector that represents a category. It enhances representation learning"
      ],
      "metadata": {
        "id": "8rhnLo7jOY1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding_column is used to represent high-dimensional categorical features in a lower-dimensional space."
      ],
      "metadata": {
        "id": "Uz5jGnOnP-0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the categorical column\n",
        "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    key='education', vocabulary_list=['HighSchool', 'Bachelors', 'Masters', 'PhD'])\n",
        "\n",
        "# Convert the categorical column to an embedding column with 2D embeddings\n",
        "education_embedding = tf.feature_column.embedding_column(education, dimension=2)\n",
        "\n",
        "# Example input\n",
        "features = {'education': ['Bachelors', 'PhD', 'Masters', 'HighSchool', 'Bachelors']}\n",
        "\n",
        "# Create a dense tensor from the embedding column\n",
        "tensor = tf.keras.layers.DenseFeatures([education_embedding])(features)\n",
        "\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqaMOs7-OUbt",
        "outputId": "12e61a60-92da-468e-9aaf-8f9a7f4462f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-191791fd7335>:8: embedding_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.5059846  -0.26062796]\n",
            " [ 0.9991912  -0.21856011]\n",
            " [ 0.45055795 -0.29276913]\n",
            " [ 0.7213919   0.11462164]\n",
            " [ 0.5059846  -0.26062796]], shape=(5, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the categorical column\n",
        "words = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    key='words', vocabulary_list=['cat', 'dog', 'bird', 'fish', 'elephant'])\n",
        "\n",
        "# Convert the categorical column to an embedding column with word embeddings\n",
        "word_embedding = tf.feature_column.embedding_column(words, dimension=3)\n",
        "\n",
        "# Example input\n",
        "features = {'words': ['cat', 'dog', 'fish', 'elephant', 'bird']}\n",
        "\n",
        "# Create a dense tensor from the embedding column\n",
        "tensor = tf.keras.layers.DenseFeatures([word_embedding])(features)\n",
        "\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZUyGFZtQkPv",
        "outputId": "76528ae0-f7f3-46ac-f1c8-37e345e201f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.5343626   0.38480031 -1.083207  ]\n",
            " [-0.57303953 -0.12368282 -0.13121653]\n",
            " [ 0.08513737  0.16181467  0.41971907]\n",
            " [ 1.1402742  -0.03480695 -0.8175274 ]\n",
            " [-0.05962566  0.21273744 -0.34122324]], shape=(5, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.  Using Feature Columns for Parsing\n"
      ],
      "metadata": {
        "id": "A90TDbriQ2Yx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The make_parse_example_spec function generates a parsing spec based on the feature columns provided. This is useful when you want to parse tf.train.Example records."
      ],
      "metadata": {
        "id": "xIoWO6cvRwID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define feature columns\n",
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column('latitude'),\n",
        "    tf.feature_column.numeric_column('longitude'),\n",
        "    tf.feature_column.categorical_column_with_vocabulary_list('ocean_proximity', ['NEAR BAY', 'INLAND', 'NEAR OCEAN', 'ISLAND'])\n",
        "]\n",
        "\n",
        "# Generate the parsing spec\n",
        "parse_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n",
        "\n",
        "# Example serialized Example\n",
        "example = tf.train.Example(features=tf.train.Features(feature={\n",
        "    'latitude': tf.train.Feature(float_list=tf.train.FloatList(value=[37.7749])),\n",
        "    'longitude': tf.train.Feature(float_list=tf.train.FloatList(value=[-122.4194])),\n",
        "    'ocean_proximity': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b'NEAR BAY']))\n",
        "}))\n",
        "\n",
        "serialized_example = example.SerializeToString()\n",
        "\n",
        "# Parse the example\n",
        "parsed_features = tf.io.parse_single_example(serialized_example, parse_spec)\n",
        "print(parsed_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVOOcTqXRjyA",
        "outputId": "bb4059ba-4c7c-4c9c-b7a6-bed79489e230"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-40c8882bac03>:11: make_parse_example_spec_v2 (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ocean_proximity': SparseTensor(indices=tf.Tensor([[0]], shape=(1, 1), dtype=int64), values=tf.Tensor([b'NEAR BAY'], shape=(1,), dtype=string), dense_shape=tf.Tensor([1], shape=(1,), dtype=int64)), 'latitude': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([37.7749], dtype=float32)>, 'longitude': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-122.4194], dtype=float32)>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define feature descriptions\n",
        "feature_descriptions = {\n",
        "    'latitude': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'longitude': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'ocean_proximity': tf.io.FixedLenFeature([], tf.string),\n",
        "    'median_house_value': tf.io.FixedLenFeature([], tf.float32)\n",
        "}\n",
        "\n",
        "# Define the parse_examples function\n",
        "def parse_examples(serialized_examples):\n",
        "    examples = tf.io.parse_example(serialized_examples, feature_descriptions)\n",
        "    targets = examples.pop('median_house_value')  # separate the targets\n",
        "    return examples, targets\n",
        "\n",
        "# Create example data\n",
        "examples = [\n",
        "    {\n",
        "        'latitude': 37.7749,\n",
        "        'longitude': -122.4194,\n",
        "        'ocean_proximity': 'NEAR BAY',\n",
        "        'median_house_value': 1000000.0\n",
        "    },\n",
        "    {\n",
        "        'latitude': 34.0522,\n",
        "        'longitude': -118.2437,\n",
        "        'ocean_proximity': 'INLAND',\n",
        "        'median_house_value': 850000.0\n",
        "    },\n",
        "    {\n",
        "        'latitude': 40.7128,\n",
        "        'longitude': -74.0060,\n",
        "        'ocean_proximity': 'NEAR OCEAN',\n",
        "        'median_house_value': 1200000.0\n",
        "    }\n",
        "]\n",
        "\n",
        "# Write the example data to a TFRecord file\n",
        "tfrecord_filename = 'internal_data.tfrecord'\n",
        "with tf.io.TFRecordWriter(tfrecord_filename) as writer:\n",
        "    for example in examples:\n",
        "        feature = {\n",
        "            'latitude': tf.train.Feature(float_list=tf.train.FloatList(value=[example['latitude']])),\n",
        "            'longitude': tf.train.Feature(float_list=tf.train.FloatList(value=[example['longitude']])),\n",
        "            'ocean_proximity': tf.train.Feature(bytes_list=tf.train.BytesList(value=[example['ocean_proximity'].encode()])),\n",
        "            'median_house_value': tf.train.Feature(float_list=tf.train.FloatList(value=[example['median_house_value']]))\n",
        "        }\n",
        "        tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "# Set up the dataset\n",
        "batch_size = 2\n",
        "dataset = tf.data.TFRecordDataset([tfrecord_filename])\n",
        "dataset = dataset.repeat().shuffle(10000).batch(batch_size).map(parse_examples)\n",
        "\n",
        "# Example iteration over the dataset\n",
        "for batch in dataset.take(1):\n",
        "    features, targets = batch\n",
        "    print('Features:', features)\n",
        "    print('Targets:', targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FneIsb0PR0yE",
        "outputId": "4ed00462-3d03-40e2-9198-c6200e5a6800"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: {'latitude': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([40.7128, 40.7128], dtype=float32)>, 'longitude': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-74.006, -74.006], dtype=float32)>, 'ocean_proximity': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'NEAR OCEAN', b'NEAR OCEAN'], dtype=object)>}\n",
            "Targets: tf.Tensor([1200000. 1200000.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.  Using Feature Columns in Your Models\n"
      ],
      "metadata": {
        "id": "I99pF6g4Rixp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define feature columns\n",
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column('latitude'),\n",
        "    tf.feature_column.numeric_column('longitude'),\n",
        "    tf.feature_column.categorical_column_with_vocabulary_list('ocean_proximity', ['NEAR BAY', 'INLAND', 'NEAR OCEAN', 'ISLAND']),\n",
        "    tf.feature_column.numeric_column('median_house_value')\n",
        "]"
      ],
      "metadata": {
        "id": "sTg9i0vSRkGo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invent example data\n",
        "examples = [\n",
        "    {\n",
        "        'latitude': 37.7749,\n",
        "        'longitude': -122.4194,\n",
        "        'ocean_proximity': 'NEAR BAY',\n",
        "        'median_house_value': 1000000.0\n",
        "    },\n",
        "    {\n",
        "        'latitude': 34.0522,\n",
        "        'longitude': -118.2437,\n",
        "        'ocean_proximity': 'INLAND',\n",
        "        'median_house_value': 850000.0\n",
        "    },\n",
        "    {\n",
        "        'latitude': 40.7128,\n",
        "        'longitude': -74.0060,\n",
        "        'ocean_proximity': 'NEAR OCEAN',\n",
        "        'median_house_value': 1200000.0\n",
        "    },\n",
        "    {\n",
        "        'latitude': 36.7783,\n",
        "        'longitude': -119.4179,\n",
        "        'ocean_proximity': 'INLAND',\n",
        "        'median_house_value': 650000.0\n",
        "    },\n",
        "    {\n",
        "        'latitude': 32.7157,\n",
        "        'longitude': -117.1611,\n",
        "        'ocean_proximity': 'NEAR BAY',\n",
        "        'median_house_value': 950000.0\n",
        "    }\n",
        "]\n",
        "\n",
        "# Write the example data to a TFRecord file\n",
        "tfrecord_filename = 'internal_data.tfrecord'\n",
        "with tf.io.TFRecordWriter(tfrecord_filename) as writer:\n",
        "    for example in examples:\n",
        "        feature = {\n",
        "            'latitude': tf.train.Feature(float_list=tf.train.FloatList(value=[example['latitude']])),\n",
        "            'longitude': tf.train.Feature(float_list=tf.train.FloatList(value=[example['longitude']])),\n",
        "            'ocean_proximity': tf.train.Feature(bytes_list=tf.train.BytesList(value=[example['ocean_proximity'].encode()])),\n",
        "            'median_house_value': tf.train.Feature(float_list=tf.train.FloatList(value=[example['median_house_value']]))\n",
        "        }\n",
        "        tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "        writer.write(tf_example.SerializeToString())"
      ],
      "metadata": {
        "id": "AAnaUKOoUau2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature descriptions\n",
        "feature_descriptions = {\n",
        "    'latitude': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'longitude': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'ocean_proximity': tf.io.FixedLenFeature([], tf.string),\n",
        "    'median_house_value': tf.io.FixedLenFeature([], tf.float32)\n",
        "}\n",
        "\n",
        "# Define the parse_examples function\n",
        "def parse_examples(serialized_examples):\n",
        "    examples = tf.io.parse_example(serialized_examples, feature_descriptions)\n",
        "    targets = examples.pop('median_house_value')  # separate the targets\n",
        "    return examples, targets\n",
        "\n",
        "# Set up the dataset\n",
        "batch_size = 2\n",
        "dataset = tf.data.TFRecordDataset([tfrecord_filename])\n",
        "dataset = dataset.repeat().shuffle(10000).batch(batch_size).map(parse_examples)"
      ],
      "metadata": {
        "id": "sbDeuGMOUb5f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the feature columns without the target\n",
        "ocean_proximity = feature_columns[2]\n",
        "ocean_proximity = tf.feature_column.indicator_column(ocean_proximity)\n",
        "columns_without_target = [\n",
        "    feature_columns[0],\n",
        "    feature_columns[1],\n",
        "    ocean_proximity  # Use the wrapped column\n",
        "]\n",
        "\n",
        "# Define the Keras model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.DenseFeatures(feature_columns=columns_without_target),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"mse\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Determine steps_per_epoch\n",
        "steps_per_epoch = len(examples) // batch_size\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=5)\n",
        "\n",
        "print(history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p13tK3ItUfbW",
        "outputId": "2e463f5f-fdbc-499a-fa3f-99433eba30fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 23ms/step - loss: 44163623991377920.0000 - accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 200828300777926286517469184.0000 - accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 891875386831199361507403926129868800.0000 - accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 30ms/step - loss: inf - accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 30ms/step - loss: inf - accuracy: 0.0000e+00\n",
            "{'loss': [4.416362399137792e+16, 2.008283007779263e+26, 8.918753868311994e+35, inf, inf], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TF Transform\n",
        "For improving data pre-processing speed in Production with this feature columns encoding process"
      ],
      "metadata": {
        "id": "2GGIYji_TwfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_transform as tft\n",
        "\n",
        "def preprocess(inputs):  # inputs is a batch of input features\n",
        "  median_age = inputs[\"housing_median_age\"]\n",
        "  ocean_proximity = inputs[\"ocean_proximity\"]\n",
        "  standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))\n",
        "  ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
        "  return {\n",
        "    \"standardized_median_age\": standardized_age,\n",
        "    \"ocean_proximity_id\": ocean_proximity_id\n",
        "  }"
      ],
      "metadata": {
        "id": "mTNyKvdqT-DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The TensorFlow Datasets (TFDS) Project\n"
      ],
      "metadata": {
        "id": "jMHXrV-0UVzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset = tfds.load(name=\"mnist\")\n",
        "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "c1809bbf275648ec8fbababf7b5239e9",
            "aaee591cf686474da6e1145d1450b698",
            "ece6490e8f494f5bb91a82ab01529d09",
            "49db65a6e1fd427b8fc761c80d0e8262",
            "e65f26adc77e4206bd8677a29e83ebb4",
            "6f00e8fd446744f2b10e8cd41f48d0bc",
            "395b13563fc242b7ad197bb0f5a0e78c",
            "1f17f4cb011a4b55a1b95355a60f6f1a",
            "f1b055ea4d82433898663b79baba66cf",
            "4fd90dd207104424ad6340ad6814ccb6",
            "e0aa43d828e84c88a3b69680f1fbe66e"
          ]
        },
        "id": "DFj-4Mt7UWbs",
        "outputId": "e7f635e6-cf13-4917-9cf0-acd1f07a8585"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1809bbf275648ec8fbababf7b5239e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = mnist_train.repeat(5).batch(32).prefetch(1)\n",
        "for item in mnist_train:\n",
        "  images = item[\"image\"]\n",
        "  labels = item[\"label\"]"
      ],
      "metadata": {
        "id": "-iZHgVdcU1CC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = mnist_train.repeat(5).batch(32)\n",
        "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
        "mnist_train = mnist_train.prefetch(1)"
      ],
      "metadata": {
        "id": "HFcgbvl0VmQu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "source": [
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "\n",
        "mnist_train = dataset[\"train\"].repeat().prefetch(1)\n",
        "# Replace ... with actual Keras layers\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\")\n",
        "model.fit(mnist_train, steps_per_epoch=60000 // 32, epochs=5)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyp6ew2XV5tP",
        "outputId": "61bb6f73-1ba8-49c0-bd7f-db2029281a25"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 6ms/step - loss: 2.6439\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3026\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3026\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78eb4ec5ebc0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}